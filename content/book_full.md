COMMAND

THE PAGE

\>\_The Ai-Assisted Way To Improve Your Writing, Publish Your Ideas
Faster, And Future-Proof Your Creative Career

**By Charlie Deist**

**www.vergili.us**

Copyright Â© 2023 Charlie Deist

All rights reserved. No part of this book may be reproduced,
distributed, or transmitted in any form or by any means, including
photocopying, recording, or other electronic or mechanical methods,
without the prior written permission of the publisher, except in the
case of brief quotations embodied in critical reviews and certain other
noncommercial uses permitted by copyright law.

ISBN: 9798870811802

First Edition: December 2023

Printed in the United States of America

Vergilius Publishing

Berkeley, CA

For Sadie

[CONTENTS]{.underline}

[Index of tools [vii](#_Toc152566395)](#_Toc152566395)

Introduction - [THE RISE OF THE CYBORG WRITER
[1](#_Toc152566396)](#_Toc152566396)

**[\
PART 1 - NATURAL LANGUAGE PROGRAMMING]{.underline}**

Chapter 1 - [THE HOTTEST NEW PROGRAMMING LANGUAGE
[12](#_Toc152566397)](#_Toc152566397)

Chapter 2 - [PROMPT ENGINEERING 101
[20](#_Toc152566398)](#_Toc152566398)

CHAPTER 3 - [AI ALCHEMY
..........................................................[34](#_3tk96yhgn458)](#_3tk96yhgn458)

**[\
PART 2 - THE AI-POWERED CONTENT ENGINE]{.underline}**

Chapter 4 - [The TaaS Revolution [43](#_Toc152566400)](#_Toc152566400)

Chapter 5 - [POLISHING [47](#_Toc152566401)](#_Toc152566401)

Chapter 6 - SEO [Show Notes [54](#_Toc152566402)](#_Toc152566402)\
**[\
PART 3 - BECOMING A "CODER"]{.underline}**

Chapter 7 - [Of Pyramids & Diamonds
[64](#_Toc152566403)](#_Toc152566403)

Chapter 8 - [CAPTURE [71](#_Toc152566404)](#_Toc152566404)

Chapter 9 - [ORGANIZE [75](#_Toc152566405)](#_Toc152566405)

Chapter 10 - [DISTILL [83](#_Toc152566406)](#_Toc152566406)

Chapter 11 - [EXPRESS, PT. 1 [90](#_Toc152566407)](#_Toc152566407)

Chapter 12 - [EXPRESS PT. 2 [96](#_Toc152566408)](#_Toc152566408)

Chapter 13 - [Refining, Editing, & Finishing Touches
[102](#_Toc152566409)](#_Toc152566409)\
**[\
PART 4 - CODing YOUR MINIMUM VIABLE MASTERPIECE]{.underline}**

Chapter 14 - [Capture and Organize
[113](#_Toc152566410)](#_Toc152566410)

Chapter 15 - [Distill & Express [123](#_Toc152566411)](#_Toc152566411)

Conclusion - [Why Write a Book? [128](#_Toc152566412)](#_Toc152566412)

[About the Author [133](#_Toc152566413)](#_Toc152566413)

[]{#_Toc152566395 .anchor}Index of tools

Â 

**ChatGPT --** AI language model developed by OpenAI that can generate
human-like text based on the prompts it receives.

**Claude** -- An AI language model developed by Anthropic, designed to
interact in a conversational manner and assist with a range of tasks
including writing and creative brainstorming.

**Notion** -- A customizable all-in-one workspace for note-taking,
knowledge and data management, project management, and collaboration.

**Grammarly --** A writing assistant offering spelling and grammar
suggestions (including full AI rewrites) that integrates with any app
where you type.

**Otter.ai** -- A transcription service that uses AI to convert speech
to text in real time.

**Descript** -- A multimedia editing tool that allows users to edit
audio and video by editing the text transcript of the recording.

**Riverside.fm** -- A platform for recording podcasts and videos with
high-quality audio and video.

**Substack** -- A platform that allows writers and creators to publish
and monetize newsletters and podcasts through paid subscriptions.

**Save to Notion --** A browser extension for capturing external sources
into your Notion content database with just a few clicks.

[INTRODUCTION]{.underline}

[]{#_Toc152566396 .anchor}THE RISE OF THE CYBORG WRITER

"AI won't take your job. It's somebody using AI that willÂ take your
job."

--Â Richard Baldwin

Garry Kasparov's hand hovered, then committed to his move: Knight to A5.

In chess, it's often said that "a knight on the rim is grim," and as the
grandmaster leaned back in his chair, the grim reality of his position
against IBM's "Deep Blue" computer started to crystallize. After
alternating wins in the first two games of the six-game match, the next
three games had all ended in draws. It was down to the decisive final
game. Commentators would later assess this ill-fated move as the
beginning of the end for Kasparov -- and a harbinger of the dawn of AI
supremacy. The machine's cold, calculating moves had squeezed Kasparov's
options -- never making a flashy play but always increasing its
advantage. Under mounting pressure, Kasparov saw that he had been
outmaneuvered. Rather than allowing himself to be check-mated, he
resigned the match.

This 1997 match between Kasparov and Deep Blue marked a historic defeat
of the world's best human chess player by the industry's most powerful
machine. Although it had been close until this final game, Deep Blue's
victory was clear-cut. From that point on, the odds would only keep
tilting in the computer's favor. Today, Magnus Carlsen, who is
recognized as the best player in the world, enjoys an "Elo rating" of
2882, while computers rank well above 3400.

But a funny thing happened on the way to the AI apocalypse.

First of all, humans kept on playing chess -- robot superiority be
damned. Second, the machine did *not* remain invincible. It turned out
that the combination of a human being **and** a computer was more
powerful than the computer alone. Hence, "Cyborg Chess," where humans
and computers work together, is a sport unto itself with its own
reigning champions. In this game, creativity and cooperation with
computers are rewarded over sheer speed or brainpower alone. And here's
the thing: an *average* chess player with *above-average* skill at
wielding the computer's help can defeat a grandmaster with or without
the computer.

In 2005, Steven Cramton and Zackary Stephen, club players with ratings
of 1685 and 1398, respectively, outwitted three grandmasters in the
computer-assisted PAL/CSS Freestyle Chess Tournament. Imagine a pair of
junior varsity players outmaneuvering Shaquille O'Neal, Michael Jordan,
and Kobe Bryant in a 2-on-3 basketball game. Though less technically
skilled, perhaps, their cyborg edge delivered the win.

Fast forward to November 30, 2022. A superior level of artificial
intelligence exploded onto the scene in the form of a chatbot called
ChatGPT. Within weeks, millions of mere mortals created free ChatGPT
accounts. Its easy-to-use interface (a simple chat window) returned
human-sounding answers to questions. Tech geeks and non-techies alike
began tapping into AI's deep knowledge, learning how to prompt or train
AI for even better results. The growth of this field has no end in
sight, with recent upgrades of "multi-modal" capabilities that can turn
speech to text, text to speech, text to image, and even text to video.
This new frontier has many clamoring for regulation -- fearing
widespread economic displacement -- and more attention is being given to
the risks of artificial intelligence. Even if you haven't jumped on the
bandwagon, you've likely heard AI lingo like **large language models**,
**generative pre-trained transformers** (GPT), and Silicon Valley's
hottest new job title: prompt engineer. You will gain deep familiarity
with terminology in this book, but most regular folks don't need an
in-depth technical understanding of the "inner workings."

However, now that this technology is in the mainstream, no one should
ignore the talk of the economic transformation taking place. Fears are
being stoked again of the Great Robot Uprising that will replace humans
for good. This book will help bring comfort, especially to writers, and
calm the storm for other professions ... despite the headlines.

"[300 million jobs could be affected by latest wave of
AI](https://www.cnn.com/2023/03/29/tech/chatgpt-ai-automation-jobs-impact-intl-hnk/index.html#:~:text=300%20million%20jobs%20could%20be%20affected%20by,of%20AI%2C%20says%20Goldman%20Sachs&text=As%20many%20as%20300%20million,according%20to%20Goldman%20Sachs%20economists),"
read one CNN headline.

TechRadar reported "[Many workers are faking knowledge of AI to make
sure they aren't left
behind](https://www.techradar.com/pro/many-workers-are-faking-knowledge-of-ai-to-make-sure-they-arent-left-behind)."

A comic strip by editorial cartoonist Tom Tomorrow encapsulated the
prevailing angst among creative workers. In the cartoon, a smiling robot
tells a futuristic-looking penguin character that "soon there will be no
need for human writers and artists at all!"

"According to my algorithm," the robot declares, "everybody wins!"

But the penguin objects:

"What if... writers and artists ***want*** to do their work? And maybe
even earn a living?"

The robot assures the penguin that perhaps obsolete writers and artists
would "find new forms of creativity... leading them to *unanticipated
heights of personal expression*!"

At first blush, this reply sounds hollow. Indeed, the blend of clichÃ©s
spoken with unwarranted confidence can only be described as
"ChatGPT-esque." But maybe this cartoon robot knows something we don't.
Maybe his reply hints at a better path forward than Kasparov's sullen
resignation.

# Winners and Losers in the AI Age

During the industrialization of England in the 1800s, the arrival of the
mechanical loom gave rise to a group of anti-industrialization zealots.
The "Luddites," as they were known, made a sport out of smashing the new
warehouse-sized weaving machines. They feared that the new textile
factories would eliminate good old-fashioned high-paying weaving jobs.
And they weren't wrong*.* How many professional weavers do you know
today?

Most economists argue that the long-term result of the Industrial
Revolution was a net improvement in welfare for all. After all, fewer
people doing the same work with machines means higher overall
productivity. And higher productivity translates into higher wages.
Sure, many workers are displaced in the short run, but in time, the
unemployed get absorbed into other sectors. In theory, machines liberate
people to focus on more meaningful work. But economists also acknowledge
that new technology breeds winners and losers. The concept of
**skill-biased technical change** holds that technology tends to empower
those with *complementary* knowledge and capabilities the most. It's the
same lesson we can draw from cyborg chess: the machine is powerful, but
the real power comes from the combination of humans *and* machines.

The entire "knowledge economy" has been built around the symbiosis
between educated workers and computers that augment the ability to put
their knowledge to use. AI accelerates this phenomenon.

<figure>
<img src="./book_media/media/image1.png"
style="width:3.02703in;height:2.81912in"
alt="Men working in a factory Description automatically generated" />
<figcaption><p>The Frame-Breaking Act 1812 made smashing looms
punishable by death in the United Kingdom. (Image: Wikimedia
Commons)</p></figcaption>
</figure>

Companies like IKEA, for example, are scrambling to retrain the vast
numbers of customer support workers who have been replaced by its
automated Chatbot, Billie. Billie can resolve thousands of customer
queries without fatigue or frustration, including the frequently asked,
"How do I assemble the **FLÃœRGENSHLURG**?" (a dilemma often faced by
customers when those "spare screws" turn out to be the lynchpins of
their entire sofa).

Unless you work in customer support, your job may still be safe -- for
now. However, you are at risk of being outcompeted long-term by those
who have a better grasp of these tools than you. The opening quote from
economics professor and author Richard Baldwin hints at our direction:
AI might not take your job, but someone *using* AI will. In his books,
Baldwin documents a "globotics upheaval" triggered by advances in
robotics, AI/automation, and telemigration. While lower-skilled labor
has borne the brunt of globalization and automation through the 2020s,
the latest round of AI innovation is coming for higher-skilled workers
and even creative professionals. Your CPA is at a higher risk than your
gardener of losing his job in the coming revolution -- not to AI itself
but to a super-accountant leveraging AI in his practice.

In the years ahead, the gap will widen between the skilled and the
unskilled -- the AI-assisted, and the unassisted. You stand to win or
lose to the extent that you learn to work ***with*** AI. Even the
plumbing contractor who learns to use AI to communicate better with his
clients will gain an advantage over his neo-Luddite competitors.

# **AskAI â†’ Improve Writing**

In the first months after the November 2022 release of ChatGPT, I
briefly played around with the chatbot. I found the experience amusing,
asking questions like "What should I make for breakfast based on the
four ingredients in my fridge?" But like many others, my overriding
thought was, "Okay, ChatGPT is neat -- but *how does AI help me do my
job better*?"

My "aha" moment with AI came some three months later, with the release
of a new suite of AI tools embedded right inside the main software
platform I use in my work as a writer and radio/podcast producer. This
platform, Notion, per their website, "is a single space where you can
think, write, and plan. Capture thoughts, manage projects, or even run
an entire company -- and do it exactly the way you want." Notion serves
as an all-in-one workspace -- combining the best elements of word
processing, spreadsheets/databases, and project management software. For
me, and millions of users, it functions as something of a "second
brain," housing everything from notes-to-self and project dashboards to
calendars, Kanban boards, to-do lists, and more. I am a huge advocate.

My primary uses for Notion include managing the content calendars for
several podcasts I produce and preparing promotional assets like show
notes and edited transcripts for publication after the hosts record
their interviews. Outside of Notion, I first convert audio recordings
from podcasts and radio shows into text using
[Otter.ai](http://otter.ai/) and Descript (more about those two tools
later). Once the audio content is converted to rough text, I load the
written version into Notion's workspace.

Refining AI-generated transcripts can be time-consuming, but over the
years, I honed the process in Notion's specialized pages and established
my own standard operating procedures. With each keystroke, I smooth out
the language, ensuring speakers sound articulate without changing their
intended meaning. These improved transcripts often became part of
anthologies as I began working with publishers to create books from the
rich material of podcasts and radio shows. Notion (and a few other side
tools) provided all that I needed to keep organized, productive, and
creative. So when Notion released the beta version of its new built-in
AI functions, I was among the first to try it out with my existing
workflows.

I highlighted a block of my rough, unedited transcript within Notion as
if I were going to reformat the text in bold or italics. But in addition
to the usual formatting options in the menu bar, Notion presented me
with a shiny *new* button labeled âœ¨**AskAI**.

Unlike OpenAI's world-famous ChatGPT, Notion's new AI function didn't
present me with an empty chat box but with a set of *commands* -- the
ability to ask AI to *do something* with my own content. The first
preset option under **AskAI** was **Improve writing**, next to an icon
of a magic wand.

So, I scrolled down, hit **Improve writing**, and waited for the
response.

"AI is writing..."

![A screenshot of a computer Description automatically
generated](./book_media/media/image2.png){width="4.159535214348207in"
height="3.8952515310586175in"}

Now, it was time for the big reveal -- to see how AI would perform this
task. In seconds, NotionAI cleaned up and improved the writing of an
entire block of rough transcript. Any writer worth their salt can
recognize good writing, whether crafted by humans or machines. And
NotionAI's "improved writing" was *good*. The output was concise and
logical, yet the speakers' personalities were preserved.

I suspect that many of you reading this might surmise that your job is
safe from AI replacement because of the creative nature of your work.

"Sure," you think, "AI might *someday* replace my job -- but that
someday is a long time off."

But here, Notion's AI was doing the core of *my* job -- enhancing rough
transcripts -- and doing it better. My previous editing process
involving hundreds of decisions had been simplified to just three
clicks:

Highlight text â†’ âœ¨**AskAI** â†’ **Improve writing**.

In just a few more minutes and a dozen more commands, NotionAI helped me
polish the full podcast transcript, saving me hours of work.

After seeing NotionAI do my job better than me, I felt a budding
sympathy with the penguin from Tom Tomorrow's cartoon. His concerns were
*my* concerns. His struggle was *my* struggle. What if I *wanted* to
keep doing my job the old-fashioned way? My attitude towards AI shifted
from skepticism into a mix of curiosity and apprehension. If AI could
transform transcripts with such ease, what purpose would I serve in the
process?

Was I about to become a victim of the "great replacement" of workers
with machines?

Or, perhaps, would enlisting AI free me from lower-level editing tasks?
Would it allow me to focus on higher-order tasks, such as repurposing
transcripts into valuable content like innovative articles and books?

Instead of resisting technological progress like the Luddites and
smashing my computer, I could choose to master the art of AI-assisted
writing. I could learn everything about the emerging craft called
"prompt engineering" or "AI whispering" to coax my desired outputs from
AI.

I had a new goal: I was going to surf the AI wave rather than drown in
its churn.

## After the Peak of Inflated Expectations

The Gartner "hype cycle" is a graphical presentation that represents the
maturity, adoption, and social application of new technology. Regardless
of the innovation in question, the public's excitement follows a
well-established roller-coaster trajectory. My own experience with AI
has followed a similar path:

<figure>
<img src="./book_media/media/image3.png"
style="width:4.5in;height:2.91806in"
alt="A graph of a graph Description automatically generated with medium confidence" />
<figcaption><p>The Gartner Hype Cycle, Â (2024, January 16). In
Wikipedia.</p></figcaption>
</figure>

First came the triggering innovation -- in this case, AI tools like
ChatGPT. Next, with high hopes, I subscribed to every AI newsletter,
followed every thought leader, and signed up for every new AI tool
claiming to revolutionize the writing process. For a time, my entire
Twitter feed was flooded with infinite variations of the same "viral"
hook:

> "16-year-olds are making \$100ks using ChatGPT. ðŸ”¥ðŸ”¥ðŸ”¥ ***Retweet this
> to get the free guide to becoming an AI millionaire***. ðŸ‘‡ðŸ‘‡"

But the content never lived up to my inflated expectations whenever I
fell for the hype -- retweeting or signing up for the free trial. The
"free guides' gave generic and superficial advice. It was clear that
those hyping overnight AI success lacked experience and were often
faking their own success. From large to smaller applications, AI didn't
appear to offer a competitive advantage for the writing profession. AI
technology on its own could not forge a writer's business model. Nor did
these tools provide ordered steps to complete specific tasks that
writers face (common "use cases" per tech jargon).

I was sliding into the trough of disillusionment.

Soon, however, my disillusionment gave way to a new, more gradual
discovery process -- the "slope of enlightenment" -- in which I realized
that I already held the keys to what many were scrambling to unlock. My
simple use case of transforming raw, human-generated content into clear,
polished, and logical prose was a natural complement to AI's strengths.

I found that the solution didn't lie in any single "killer app" or
"superprompt" but in developing an intuitive feel for how to command AI,
coupled with a few basic principles and a framework for getting
consistent results. AI is not a machine for *generating* answers or
polished content out of thin air. Instead, it's a tool for
*transforming* and refining human-generated ideas and inputs. This
distinction between tools and machines is subtle. Whereas a machine is
designed to be "foolproof" -- such that any fool can operate it -- a
tool requires skilled hands to operate. There is a world of difference
between AI-generated content, churned out by a machine, and
AI-*assisted* content, in which you leverage AI as a tool in the writing
process.

## Level Up or Go Extinct

In the nine months since my initial epiphany, I have developed an
effective step-by-step system for integrating AI into the writing
process. My method combines human creativity with AI commands at key
junctions. This targeted human-AI collaboration accelerates and elevates
every stage -- from ideation to editing.

Feeding AI the right prompts and source material, AI can organize,
distill, and build upon your purest ideas -- speeding up the writing
process while maintaining the quality and specificity of ideas. It can
clarify your thinking and purify the signal from your noisy brainstorms.
Beyond improving sloppy writing or a rough AI-generated transcript, it
can help structure a logical argument, fill in the gaps, and smooth
awkward transitions. And it can turn a paragraph of text (like this one)
into a bullet point list like this:

But wait... there's more. How else can AI help you? It can...

-   Rewrite text in the voice and style of another person

-   Extract follow-up "action items" from a meeting transcript

-   Simplify complex scientific papers for easier understanding

-   Translate complex concepts into accessible analogies or metaphors

-   Offer feedback on tone, readability, and alternative phrasing

-   Provide instant translations for foreign language text

-   Identify repetitive words or phrases and suggest synonyms

In the pages that follow, you will learn in greater detail how to
accomplish all of these sub-tasks -- without signing up for a dozen
different subscriptions. By the end, you will understand your vital role
as the human driver behind the AI-assisted creative process, so you can
future-proof your career in the years to come. While the specific tools
may evolve and the technology will advance, demand will only grow for
high-skilled, AI-augmented knowledge workers. AI equips us with new
capacities to transform, refine, and enhance text, unlocking greater
potential. Yet humans must provide the judgment to steer these
technologies toward ethical, constructive ends, and supply the
imagination to conceive what we choose to write.

Going forward, you have two options.

Will you recoil at the rapid pace of change and resign yourself to
potential obsolescence?

Or will you build complementary skills to work *with* AI that make you
irreplaceable?

Within five years, if you level up, telling people, "I'm a writer,"
could carry more prestige than saying, "I'm a doctor." AI-assisted
writing salaries could rival those of software engineers. With the
emergence of AI language models like GPT-4, English is transforming into
the hottest new programming language. You can now "code" through
conversational prompts. No technical degrees are required -- just a
keyboard, an internet connection, and a willingness to experiment.

Part 1

Natural Language Programming

[CHAPTER 1]{.underline}

[]{#_Toc152566397 .anchor}THE HOTTEST NEW PROGRAMMING LANGUAGE IS...
ENGLISH?

"Prompt Engineering is natural language programming."

-- Elon Musk

In 1941, a brash 25-year-old named Orson Welles released his first film.
Having never worked in Hollywood or studied moviemaking, he approached
the project with sheer ignorance. He knew little to nothing of the
standard conventions of lighting, camera angles, or story structure.

"There's no confidence to equal it," he later remarked of his novice
mindset during an interview in which he reflected on his early career.

Unbound by theoretical impossibilities, Welles embodied the essence of
an "auteur" -- a filmmaker whose personal influence and artistic control
over his movie were so profound that he was regarded as the *author* of
the film -- not just its writer, director, and producer. In the process
of making his first film, he pioneered techniques like deep-focus
cinematography and non-linear storytelling. *Citizen Kane* is now
regarded as one of the most influential films ever made. But in 1941, it
was a shock to the system. Welles disregarded the rules and forged his
own path, treating the film medium as a blank canvas, unconstrained by
the gatekeepers of tradition.

"It's only when you know something about a profession that I think
you're timid or careful," he observed. "I thought you could do anything
with a camera that the eye... or the imagination could do. And if you
come up from the bottom in the film business, you're taught all the
things that the cameraman doesn't want to attempt for fear he will be
criticized for having failed."

Welles was also lucky to have a cameraman who didn't mind failing from
time to time and who told him at the outset that there was nothing
special about camera work -- nothing, that is, that he "couldn't learn
in half a day."

"The Great Mystery that requires 20 years doesn't exist in any field,"
Welles added, "and certainly not in the camera."

To some, artificial intelligence may seem like a great mystery. But the
basics can be learned in much less than half a day (more like half an
hour). Writers and content creators who choose to work with artificial
intelligence find themselves in a similar position to Welles as he
embarked on his masterwork. Just as Welles pioneered new filmmaking
techniques, unbound by convention, today's writers -- or anyone who
works with language, for that matter -- can explore the potential of AI
models without being constrained by preconceptions of what is possible.

If you worry that you lack the expertise to use this technology, you are
in a perfect position to learn the techniques in this book. Like Welles,
your ignorance may be your greatest asset.

## The Language Basics of AI

There is much hype (and confusion) around the coveted role of "prompt
engineer." San Francisco-based AI company Anthropic was offering a
\$350,000 salary to top prompt engineering talent. Those back-end jobs
demand a variety of technical coding skills and understanding of AI
technology. But the skill level necessary to proficiently command AI has
down-shifted and requires much less experience.

This lowered barrier to entry came about with the advent of Large
Language Models (LLMs) -- the breakthrough technology behind AI
assistants like ChatGPT.

Although the inner workings of LLMs remain opaque to most, these AI
architectures enabled a paradigm shift. For the first time, anyone
fluent in a natural language could easily interact with advanced
intelligence. As Elon Musk concisely described this breakthrough
capability, "Prompt Engineering is natural language programming." In
other words, previously it took specialized coding skills to operate AI
systems, whereas now plain language prompts can command powerful
functionalities.

Former Tesla AI Director Andrej Karpathy has labelled this innovation
"Software 3.0," comparing it to the revolution that came with graphical
user interfaces (GUIs). Those intuitive windows and menus opened
personal computing to a far wider population by replacing arcane code
terminals. Similarly, today's AI systems allow anyone to accomplish
complex tasks just by expressing goals conversationally instead of
demanding coding skills. The role of "programmer" itself is evolving
from meticulously scripting logic to providing high-level prompts that
steer generative algorithms. Just as GUIs democratized software access,
natural language interaction makes advanced AI functionality available
to anyone who can write or speak.

Hence, Karpathy's now-viral tweet, which may go down in history as the
beginning of a new era in both writing and programming:

![A screenshot of a social media post Description automatically
generated](./book_media/media/image4.png){width="4.281155949256343in"
height="1.4098742344706912in"}

Despite the technical-sounding name, prompt engineering is less about
technical mastery and more about the artful application of language when
communicating with AI. "Prompt engineering" is a misnomer that suggests
a high level of technical understanding when, in fact, that's
unnecessary outside of the upper echelons of the AI industry. I prefer
the simple term, prompt *writing* over prompt *engineering*, because you
don't need advanced knowledge of the underlying mechanics of the large
language models to engage in the subtle art of prompting AI. All you
need is a good understanding of the English language and a few core
principles.

If you've never used a tool like ChatGPT before, you will be greeted by
a chat window and a greeting, "How can I help you today?" This friendly
assistant replaces the blinking "command line" terminal of yore. This
chat "assistant" understands regular language and can execute a wide
variety of commands related to regular language as well as computer
code. It can generate coherent writing on any imaginable topic,
translate between languages, and even parse code and extract insights
from large datasets.

![A screenshot of a chat Description automatically
generated](./book_media/media/image5.png){width="4.5in"
height="3.126388888888889in"}With these changes, writing will become
less about drafting perfect polished prose. AI-powered tools like
Grammarly have already automated editing. Instead, the writing process
will involve thinking through *what you want to say* at a high level and
then guiding the language model to assemble your ideas in the most
logical sequence.

However, this does not mean that foundational programming or writing
skills become obsolete. Writers and programmers who leverage "natural
language programming" in their work will still need to be able to
recognize what good writing and solid code look like, respectively. Core
competencies will remain essential in their respective fields, even as
the tools we use to apply them evolve.

## Will Prompt Engineering Become Redundant?

The introduction of chat windows where plain English is used to interact
with AI has significantly improved the archaic "command line" interface.
Plus, for those seeking an even more straightforward experience than
conversational chat, hundreds of helpful, new applications have been
customized for specific recurring situations or common use cases. These
tailored apps are all built upon the foundational architecture of LLMs
and use AI to generate specialized content.

For instance, Tl;dv (short for "too long, didn't view") is a GPT-powered
meeting recorder for Google Meet and Zoom. Per the Tl;dv website
(tldv.io), their AI meeting tool "records, transcribes, takes
timestamped notes, and shares insights" across an organization allowing
for "smarter follow-ups and better learnings." Zoom has incorporated a
similar feature, producing meeting notes without having to use ChatGPT
to manually input transcripts and specific prompts. Similarly, tools
like Copy.ai, WordTune, and Jasper.ai are designed to assist with common
writing tasks such as editing and polishing. LinkedIn (linkedin.com) now
offers a new AI-powered, tailored experience encompassing "everything
from gaining deeper insights into crucial topics to receiving
personalized career action suggestions." All these interactions are
based on simple inputs -- with no prompting required.

Based on this trend, OpenAI CEO Sam Altman speculates that the skill of
prompt engineering will soon be integrated into these mass-market AI
products, such that average users will not need to know how to write and
design effective prompts. As of the time of writing, OpenAI just
announced its own app store, where anyone can sell their own "custom
GPTs," containing pre-programmed instructions. Users of these GPTs will
be able to accomplish an even wider variety of tasks without crafting
their own prompts, and instead following the instructions of the app
that has been designed for their purposes.

At the opposite end of the spectrum from Altman, others predict that
nearly 50% of all jobs in the future will be "prompt engineering" jobs
on some level. These roles could encompass custom GPT developers who
specialize in building tailored AI apps, content curators responsible
for optimizing AI-generated content, and consultants offering expertise
in fine-tuning AI interactions to meet specific industry needs.

More likely than either extreme is a middle path. Basic prompt literacy
will be assumed despite the proliferation of custom GPTs and AI-powered
tools with preset prompts. In some professions, it will become a core
competency, just as digital proficiency rose in importance with the
spread of computers.

There will be some percentage of specialized AI engineers who understand
the underlying code and architecture. But there will be many more
natural language programmers who write their own prompts or even create
their own chatbots for their specific use cases. For the latter, deep
intuitive knowledge of prompting will be essential. You will need to be
able to customize your own prompts for your own use cases and understand
how different inputs or "elements" of prompts can be designed to deliver
the exact outputs you want. Learning prompt design yourself is more
empowering than relying on overpaid engineers to make one-size-fits-all
tools. When relying on prepackaged prompts and AI writing tools, you
face a trade-off between their ease of use and the limitations they
impose.

Writers, or anyone with strong language abilities, has an advantage here
in this emerging field of natural language programming. Investing
further in prompting skills lets you unlock the full potential of LLMs.
Don't settle for presets -- instead, craft your own prompts tailored to
your own goals.

## A Peek Under the Hood of a Large Language Model

So, what does the aspiring independent prompt writer need to know about
the underlying technology?

If you want to understand the architecture of LLMs, one good place to
start is an article called ***large language models, explained with a
minimum of math and jargon***, by Timothy B. Lee and Sean Trott. In it,
they write:

> "Explaining how large language models work is like opening the hood of
> your car and finding it full of lively squirrels adjusting valves. You
> can see the creatures are optimizing something, but tracing all their
> scurrying would take months."

Who has time for that? For our purposes, all we need are the basics.
Large language models (LLMs) like GPT-3 generate text by predicting the
likelihood of the next word in a sequence, considering both the
preceding words and the broader context of the prompt. These *models*
(as I'll refer to them) develop their predictive capabilities through a
process known as "training," wherein they analyze vast bodies of textual
data. This data is often sourced from the public domain, including a
wide array of internet-based text. For instance, GPT-3 was trained on a
dataset comprising over a trillion words.

In the training process, words are mathematically modeled as vectors --
essentially, points within a high-dimensional "word space." This
technique is part of what's known as word embeddings or vector
databases. The concept of a "meaning aura" around a word posits that
words convey more than their explicit definitions, akin to the bulk of
an iceberg lying unseen beneath the water's surface. For the word
"computer," one doesn't only think of its dictionary meaning but also
conjures up a network of related concepts from "hardware" to "software."
This intricate matrix of associations, presumptions, and implied
meanings enriches communication, allowing for nuanced interactions such
as sarcasm, where a shared, tacit understanding of the context is
essential.

There is vigorous debate around the question of whether LLMs
*understand* language or are just advanced pattern recognizers -- a
glorified "auto-complete" function. Some downplay the capabilities of AI
by noting that, at the root, these tools are "just predicting the next
most likely word." But this criticism falls flat. Ilya Sutskever, one of
the co-founders of OpenAI, explains why this statistical learning of
LLMs equates to a deeper understanding of language:

> "So, the way to think about it is that when we train a large neural
> network to accurately predict the next word in lots of different texts
> from the Internet, what we are doing is that we are learning a world
> model. ... It may look on the surface... like learning correlations in
> text, but it turns out that to "just learn" the statistical
> correlations in text, to compress them really well, **what the neural
> network learns is** some representation of the process that produced
> the text. This text is actually aÂ projection of the world\...
>
> ... \[W\]hat the neural network is learning is more and more aspects
> of the world, of people, of the human conditions, their hopes, dreams,
> and motivations, their interactions in the situations that we are in.
> And the neural network learns a compressed, abstract, usable
> representation of that."

Large language models (LLMs) have begun to outperform humans in specific
areas, notably in tasks such as translation. However, these models still
have limitations. They are good at discrete tasks but tend to go off the
rails when given complex or multi-step jobs. They have limited long-term
memory and primitive deductive reasoning. Thus they cannot *connect*
concepts over time without human supervision. Finally, their expertise
is limited to the "congealed knowledge" of their training data. As a
result, they need humans to oversee them -- to "seed" them with
specific, contextualized information, and guide them toward useful
responses.

Whether you call it prompt engineering or prompt writing, working with
AI requires you to be able to express your aims and objectives in
English. This, in turn, requires little more than being able to think
for yourself -- unconstrained by what others say is possible. As we turn
the page to the practical steps of AI-assisted writing, begin to think
of yourself as an "AI auteur." Become a prompt writer, director, editor,
and producer, all bundled into one. The upcoming chapters will build
upon this fundamental understanding of LLMs in an interactive manner,
empowering you to harness this novel technology for unparalleled
creative command over language.

Let's proceed with our "half-hour crash course," covering the essential
elements and principles of prompting -- the foundation necessary to let
your creativity run wild.

## Try It Now:

-   Read ***Large language models, explained with a minimum of math and
    jargon,*** by Timothy B. Lee and Sean Trott:
    https://www.understandingai.org/p/large-language-models-explained-with

-   Go to <https://chat.openai.com> and set up a free account.

-   Test out your first prompts -- don't be afraid to "mess up."

Chapter 2

[]{#_Toc152566398 .anchor}PROMPT ENGINEERING 101

The Subtle Art of AI Whispering

*"You don't have to be an engineer to be a racing driver, but you do
have to have Mechanical Sympathy."*

-- Jackie Stewart, racing driver

There's only one way to learn to steer a sailboat downwind in heavy
seas, and it's not by just sitting and reading about it. Although
studying physics, naval architecture, or fluid dynamics might give you a
conceptual underpinning, it only gets you so far on the water. After
some amount of orientation, you must take the helm and develop your own
feel for the boat's motions. At first, the motions feel tense
andÂ awkward. But soon, your subconscious begins to anticipate each
approaching swell until the boat transforms into an extension of your
very being.

British Formula One racing champion Jackie Stewart called this bond
"mechanical sympathy"--Â the indescribable metaphysical connection
between humans and their tools. While certain racecar drivers may
possess a stronger innate affinity for their vehicles, anyone can
achieve this sympathy with any tool. Developing it with Large Language
Models doesn't require you to understand what those squirrels are doing
"under the hood" with the valves. All it takes is curiosity and a
determination to learn from the inevitable mistakes and missteps.

Coupling the knowledge in this chapter with your own hands-on experience
will save you countless hours of trial and error and help you gain
mechanical sympathy more quickly. Just like sailing a boat or driving a
car, mastering AI is about getting your hands on the controls.

## Tools for Titans: The AI-Assisted Writing Tech Stack

In my work as a writer and radio/podcast producer, I rely on three AI
software tools: NotionAI, ChatGPT, and its rival, Claude.

ChatGPT is a chatbot application built on OpenAI's foundational large
language models, i.e., GPT-3 and GPT-4. Claude is Anthropic's AI chatbot
and has its own underlying LLM that powers it. (Claude was introduced in
March 2023.) Both ChatGPT and Claude are accessible through chat
interfaces and have free and upgraded ("plus") versions.

Claude is my preferred chatbot/LLM for most of my writing tasks. Claude
is often labeled as an "AI assistant," combining its natural language
intelligence with one crucial advantage for writers like me. Claude
allows users to bring their own "source material" into the conversation
as the vital context for its LLM output. We will get to that advantage
in a moment.

Notion is a cloud-based workspace tool and the Swiss Army Knife of
software. It transcends typical productivity tools by offering a unified
platform for note-taking, document creation, project management, and
database organization. Its intuitive interface allows users to create
"pages" that can contain diverse content types, supporting nested
structures for sophisticated information hierarchies. This design is
particularly beneficial for compiling detailed wikis or project
dashboards, streamlining the organization and retrieval of information
-- a boon for writers and project managers alike.

The integration of NotionAI, powered by Claude, augments Notion's
capabilities with AI-assisted functionalities. Through NotionAI, users
can access a suite of AI-driven commands, including the **Improve
writing** feature and a set of bespoke prompts that utilize Claude's
language processing strengths. Interaction with Claude is facilitated by
an API (Application Program Interface) that processes user inputs and
returns enhancements, redefining the writing process and empowering
users to "command the page." As we get deeper into natural language
processing, the dynamic potential of engaging with an intelligent
assistant within Notion's robust environment will become increasingly
apparent, unlocking new dimensions in the art of digital communication.
While many tasks in this book are manageable within Notion's sleek
interface, getting familiar with writing prompts within the chat
consoles is essential.

## The Elements of Natural Language Programming

### Prompts

At its most basic level, a prompt is a set of instructions that you
provide to a large language model. These instructions guide the model in
generating a useful response. Since language models are designed to
understand natural human language, it's best to communicate with them
simply and directly -- as you would with a human assistant.

Thus, the first step in engineering your prompts is gaining clarity
about what you want AI to *do*. You must define the problem you need AI
to solve or the task you want it to complete. A prompt cannot be
effective if the goal itself is ambiguous. If you aren't sure what you
want AI to do, try articulating your thought process as best you can.
Sometimes, the very act of putting your vague ideas into words brings
the clarity you need to proceed.

Your instructions can be framed as either **questions** or **commands**.

For example, you might ask Claude:

![](./book_media/media/image7.svg){width="4.5in"
height="1.2201388888888889in"}

In this case, the question could have just as easily been written as a
command:

![](./book_media/media/image9.svg){width="4.5in"
height="1.2201388888888889in"}

The model will infer what you mean either way.

As part of their understanding of language, LLMs also have an excellent
grasp of punctuation and write with polished spelling and grammar. Yet
they can also understand prompts with typos and grammatical
inconsistency -- reading between the lines and papering over human input
errors. Likewise, they are forgiving of imperfect syntax. My prompts are
often clunky, containing redundant words, but I ask myself, "Would a
reasonably intelligent person understand what I am asking here?" If the
answer is yes, I hit send and tweak if necessary.

### Examples vs. Instructions

While **instructions** can give the model a sense of *what* you want it
to do, **examples** will improve its understanding of *how* you want it
to do something. Examples can help convey the preferred format, tone, or
style or demonstrate the desired structure or organization of
information. Examples can also enhance instructions that might be
ambiguous without a concrete representation of the output you are
looking for

For example, while doing research for this book, I asked ChatGPT to
provide me with a list of podcasts that had been adapted into books. I
thought this was straightforward enough, but the initial response
included a list of 10 books with only loose connections to podcasts --
such as authors who were also podcast hosts. Only two of the books on
the list met the specified criteria. However, when I noted which
examples from the initial response were on point and asked again, the
accuracy of the next list was close to 100%. In other words, it
understood exactly what I wanted based on the examples.

Providing a single example of the desired output is known as
**one-shot** prompting in machine learning.

**Few-shot** prompting refers to providing a small number of examples to
guide the model's output, as I did by noting the two actual books
adapted from podcasts.

**Many-shot** prompting, on the other hand, involves providing a large
number of examples to train the model on a specific task or domain. This
type of prompting is most useful when the task requires a deep
understanding of the subject matter or when there is a need to capture a
wide range of variations and nuances. Examples might include training
the model to create content that adheres to certain technical formats,
such as legal documents, medical reports, or academic papers in a
specific citation style.

Usually, one-shot or few-shot prompting is sufficient for training AI to
give you what you want. Many-shot prompting is generally only necessary
when fine-tuning specialized LLMs -- something far beyond this book's
scope.

### Formatting

Formatting elements play a crucial role in enhancing the precision and
clarity of your prompts. You can use different formatting options to
structure your interactions effectively with the model. Here are some
formatting choices and how they can help improve your prompts:

**Quotation Marks and Delimiters:** Quotation marks and other delimiters
like (parentheses), \[square brackets\], \<angled brackets\>, etc., can
be used to set apart sections of text in your prompts. These marks, for
example, can help distinguish the instructional component of your prompt
*from* a longer piece of "source material" that you want summarized.

**Markdown Formatting:** Language models can interpret formatted input
and produce formatted output effectively. You can use various formatting
elements like bold, italics, different header sizes, and lists - both
ordered (i.e., a, b, c or 1, 2, 3) and unordered (i.e., bullet points).
A common use of markdown formatting is to create headings and
subheadings. For example, you can instruct Claude to size **headers**
according to their importance (H1 is the most important, H6 is the
least). Here's an prompt illustrating how to use the header markdown
ranking H2 to structure and organize your input:

![](./book_media/media/image11.svg){width="4.5in"
height="1.3159722222222223in"}

When interacting with Claude via the chat console, a long transcript or
multi-page document will exceed the limit for content that can be pasted
directly into the message area. Instead, the text pasted-in content will
be appended to the prompt as an attachment. The Claude chat window
includes an attachment option (indicated by a paperclip icon) to add
external content files. When you hover over this, it notes: **Add
content (5 max, 10MB each) Accepts pdfs, txt, csv, etc.**

This brings up a key distinction between Claude and ChatGPT -- the
amount of supplemental information or "context" that each chatbot can
process alongside the prompt itself.

### **Source Material and the Value of a Context Window**

The context window refers to the total amount of conversation history
and content that the chatbot can comprehend at once while generating a
response. This includes both the original prompt input and any previous
responses already generated by the model, covering the entire
back-and-forth exchange. The context window determines the extent to
which chatbots like Claude and ChatGPT can actively consider the
conversation record and any attached documents when formulating a
response.

Larger context windows require more computing resources, often referred
to as \"compute\" in AI circles. Premium tiers for Claude and ChatGPT
offer expanded context window capacities through a monthly subscription
fee, currently priced at \$20. These upgraded versions remove
limitations on token usage, which is how the total context length is
measured, and increase the size of the context window for each
conversation.

Tokens range from individual characters up to full words, depending on
the complexity. For example, in English, the word "unhappiness" can be
divided into smaller token units like "un," "happy," and "ness" to
better represent its linguistic composition.

# PROMPTING TIP: {#prompting-tip .Know-Your-Stuff1}

Even with a larger context window, you only want to provide the context
necessary for the model to perform the task at hand. Past a certain
point, there are diminishing returns to providing additional context. A
specific, targeted prompt must home in on the desired objective. Too
much context risks distracting from the core task.

For a longer prompt, it helps to repeat the basic instruction both at
the beginning and the end. While this may seem redundant, LLMs are
"biased" to put more weight on both the first and final tokens of the
prompt and less weight on the middle of the prompt. Remember, for all of
their capacity for pseudo-understanding, an LLM's basic job is still to
predict the next word, one word at a time. Thus, repeating the
instruction at the end ensures that it "remembers" exactly what it's
doing, and how to begin its response.

As of its latest update, ChatGPT imposes a context window limit of 8,000
tokens per prompt. On the other hand, Claude enables documents up to
200,000 tokens in length to be uploaded -- roughly 500 pages or 150,000
words of text.

This massive context window is what empowers Claude to incorporate more
information when tailoring responses.

My journey with Claude began in March 2023 when I secured a beta
account, providing me early access to its large context window. Its
usefulness became apparent when I discovered that I could utilize it to
generate promotional materials from hour-long transcripts, which
frequently exceeded 10,000 words. This task had previously been both
time-consuming and unpleasant. Since then, I have used Claude daily --
running thousands of prompts across hundreds of conversations and
probably costing the company enough in compute to fund a small lunar
mission.

The purpose of a large context window isn't just to handle lengthy
instructional prompts. Its real value is enabling chatbots to
incorporate more of your own content to generate tailored responses.

This supplemental "source material" might include transcripts,
documents, or passages of text that the model lacks in its training
data. With greater context, Claude can transform your unique inputs
rather than simply regurgitating boilerplate text. In this book, we'll
focus on prompts that serve to **transform your own source material**,
not just generate new content. The goal is to collaborate with Claude to
elevate your existing work. Relying on basic AI prompts -- without
providing this material -- tends to produce generic, inaccurate
responses that merely echo patterns in the training data. But by
providing source documents, you expand the model's knowledge beyond
these statistical echoes, merging your perspective with Claude's
capabilities. This tight creative coupling is the art of commanding the
page.

## Prompting Frameworks: A Shortcut to Mechanical Sympathy

In summary, the basic elements of prompting are:

-   **Instructions** -- What you want the model to do, framed as either
    a command, a question, or a continuation.

-   **Examples** -- Representations of the desired output, in terms of
    style, content, or format.

-   **Inputs** -- The details, context, constraints, or "source
    material" that the model will act upon or draw from in responding.

-   **Formatting** -- The structure of both the inputs and desired
    outputs, provided via instruction or example.

-   **Tokens** -- The units of text that the language model processes.

So far, these elements will feel abstract to anyone who has yet to
experiment with the models themselves. At this point, it's time to roll
up your sleeves and start practicing with your own simple prompts.

If you're new to prompting, I suggest borrowing an established prompting
framework -- customizing the details to your own goals and interests.
Think of these frameworks as templates or sets of guidelines for
assembling the key elements of a prompt for maximum efficacy.

### Role-Task-Format

Perhaps the most basic prompting framework is Role-Task-Format --
abbreviated as RTF -- which I learned from self-described AI geek
\@cj_zZZz (follow him on X).

You establish AI's role, the task it must complete, and the expected
output format.

For example:

![](./book_media/media/image13.svg){width="4.5in"
height="1.229861111111111in"}

Specifying a role for the model unlocks one of the greatest powers of
LLMs -- a pattern-recognition engine that can imitate either the
specific knowledge of a particular type of person, or even the
subtleties of a specific writer's voice. It might seem strange that
defining a role would improve the quality of output. "If the model is
trained on the entire sum of human knowledge," you might wonder, "why do
I need to tell it to be an expert in something that it already knows?"

The explanation likely has to do with the model's ability to narrow its
focus to a smaller corner of the training data. In this way, specifying
a role acts as useful context and a shortcut to long instructions.
Rather than wasting tokens laying out all of that context, such as
explaining to AI what constitutes "redundancy" in a blog post, you can
condense that background information into a few words: "Act as a copy
editor."

The task is the core of the instruction -- the job to be done.

Some common formats include:

-   Tables (specify what the columns and rows are)

-   Numbered/Bulleted lists

-   Summary outlines in markdown format

### RODES 

RODES stands for Role, Objective, Details, Examples, and Sense Check.
This framework is helpful when you have a specific idea of the kinds of
output you are looking for.

Here, the objective takes the role of your high-level instruction.

The details section is where you provide additional context or detailed
instructions related to the task or objective.

Examples help guide the model to the proper format, based on a certain
template or prototype -- the "kind of thing" you're looking for.

And, finally, the sense check is a way to confirm that you are on the
same page by asking at the end of the prompt, "Do you understand the
objective and the specific guidelines for the task?"

For example, you can instruct Claude (and note that the bolded
parenthetical material in the prompt can be kept or omitted):

![](./book_media/media/image15.svg){width="4.5in"
height="2.8409722222222222in"}

Claude will parrot back its understanding, before asking if it should
proceed with the task, at which point you can tell it to proceed.

If the response to the sense check seems off, you might find that you
need to fine-tune your prompt or provide more context. In the above
case, the task was straightforward enough. However, a sense check is a
valuable add-on to any complex prompt you are testing out for the first
time. When writing, for example, I will often provide a rough set of
ideas that makes sense to *me* and ask AI to repeat the main points back
to me in a way that makes more sense. In this way, you gain a mutual
understanding before proceeding to the actual task. Just as you are
working to develop "mechanical sympathy" with AI, a sense check helps AI
to gain "human sympathy" with you.

### RISEN Framework

The RISEN framework, courtesy of "Prompt Entrepreneur" Kyle Balmer
(@iamkylebalmer), takes the RTF up a notch -- providing the scaffolding
for multi-step processes:

RISEN stands for:

R - Role

I - Instructions

S - Steps

E - End Goal

N - Narrowing Constraints

For example, you could employ the following prompt:

![](./book_media/media/image17.svg){width="4.4992410323709535in"
height="3.255123578302712in"}

![](./book_media/media/image17.svg){width="4.4847222222222225in"
height="1.1152045056867892in"}

In this case, the steps, end goal, and narrowing constraints act as
subsets of your instructions. The input formatting of your step-by-step
list breaks up a complex goal into smaller chunks, which enables the
model to "think" one step at a time.

The steps also specify the format of the output: a rough, logical
outline, along with three bullet point titles for a potential article on
the thesis.

This is an extension of a prompting technique known as "chain of
thought" (CoT), which provides a natural sequence that a human might use
to think a problem through to improve the quality of the output.

### Chain of Thought (CoT)

Large language models excel at processing vast amounts of information
quickly, but they struggle with deductive reasoning, often relying on
statistical patterns rather than true reasoning. For instance, when
given a simple riddle like, "Charlie is the son of John. Who is
Charlie's father?", an LLM might not always provide the correct answer.

However, there's a prompting approach known as "Chain of Thought" (CoT)
that can enhance an LLM's performance by breaking down your prompt into
a series of logical steps, guiding the model through a structured
thinking process.

In many cases, LLMs already possess a degree of "understanding" within
their extensive training data, which allows them to navigate simple
logical problems. Nevertheless, explicitly instructing the model to
"think step-by-step" often leads to better results. This instruction
engages the model in a continuous "chain of thought," promoting a more
reasoned approach.

Chain of Thought works even better when you can provide the scaffolding
or structure for the steps themselves.

For example, instead of asking Claude or ChatGPT to write an article
based on source material, you can use a detailed CoT prompt like this:

![](./book_media/media/image19.svg){width="4.5in"
height="3.0506944444444444in"}

When using AI for outlining and writing, I typically utilize a version
of the chain-of-thought framework. However, instead of writing a single
prompt, I break the task into a *sequence* of prompts. After each step,
I can then focus on refining the output in a structured manner before
proceeding to the next step.

For example, if I want to create a blog post from an interview
transcript, I might start by prompting the AI to identify the
overarching concept. Subsequent prompts can then:

1.  Generate key supporting ideas as headers or sub-headers

2.  Review the transcript for detailed supporting points

3.  Specify the writing style, and lastly,

4.  Instruct the AI to draft each section one at a time.

Advanced AI-assisted writing relies heavily on the chain-of-thought
method, which I will describe in the next part of this book. By
structuring prompts to guide Claude step-by-step in reasoning through
tasks, you can elevate its output from the generic content people have
come to associate with ChatGPT to something that stands out for its
clarity, substance, and style.

Over time and through hands-on experience, I grasped many of the key
prompting concepts shared here organically. I learned the importance of
supplying source documents to augment Claude's knowledge. I also learned
how to provide the right balance of instructions and examples to focus
Claude's efforts. I gained an intuitive sense of how much context to
provide -- enough, but not more than necessary -- for a given task.

Even before I learned the terminology and frameworks contained in this
chapter, I found myself leveraging principles like chain of thought. I
would pose an initial high-level prompt to Claude. Then break down the
process into smaller steps, refining the AI's work at each stage. This
prompted sequence allowed greater control in sculpting the final output.

In time, without my "crash course" here, you would have also grasped
these concepts. This "book learning" is worth less than the hands-on
experience you will acquire, but I hope it will provide a shortcut to
mechanical sympathy -- that subconscious competence that must be learned
at the end through *doing*.

By now, you have already been exposed to 90% of what you need to know to
get started on your own journey. But it's that final 10% of principles
that will put you ahead of 99% of content creators using AI.

## Try it Now:

-   Sign up for a free Claude account at [claude.ai](http://claude.ai).

-   Upload or copy-paste a large text file, like a transcript of a long
    podcast interview, along with one of the customized prompting
    frameworks from this chapter.

-   Try the same prompt in a new chat dialogue but add the words: "Let's
    think step-by-step." Compare the results.

[CHAPTER 3]{.underline}

[]{#_3tk96yhgn458 .anchor}AI ALCHEMY

THE TRANSFORMATIVE POWER OF TRANSFORMATION OPERATIONS

"The changing of bodies into light, and light into bodies, is very
conformable to the course of Nature, which seems delighted with
transmutations."

-- Sir Isaac Newton

GPT: Three letters that have turned the world upside down. As we've
seen, the GPT acronym stands for "generative pre-trained transformers"
-- the breakthrough technology developed by the machine learning experts
at OpenAI. In my region ofÂ the San Francisco Bay Area,Â everyone is
talking about *generative* AI as the technology that will transform and
revitalize the tech industry. However, much of the hype around the
"generative" component of GPT has obscured the even greater breakthrough
embodied by the "T."

The *transformative* power of AI lies less in its ability to spit out
generic, rambling essays on any topic, and more in its capacity for
transforming lower-value inputs into higher-value outputs. In medieval
times, alchemists sought to transform "base" metals into precious gold
through the mythical philosopher's stone. Though the alchemists never
achieved their goal, advanced AI capabilities bring us closer to making
their metaphorical vision a reality. With the right prompts, you can
input messy, unstructured scribblings and output polished writing.

In the previous chapter, we saw how prompting techniques like
"Chain-of-Thought" can be used to guide language models step-by-step
through an incremental process; i.e., turning something like a rough
transcript into an outline for an article. We will take up this exact
task soon enough, but first, we need to take inventory of the essential
commands involved in advanced AI alchemy.

## The Basic Transformation Operations

Since Notion introduced its AI tools in March, numerous companies have
emulated its straightforward command-based interface. Recall that
Notion's innovation lies in its direct use of highlighted text as source
material for its AI to work on, streamlining the process of transforming
content. Unlike systems like Claude or ChatGPT, which require copying
and pasting text into a new context window, Notion integrates
transformation commands such as rewriting or refining directly into the
user's workflow, making your existing words and ideas the foundation for
AI-enhanced editing.

Within Notion, after you highlight a block of text and select
**"AskAI,"** you are presented with a list of prompts or commands:

-   **Improve Writing**

-   **Simplify Language**

-   **Change Tone**

-   **Summarize**

-   **Make Shorter/Longer**

-   **Translate**

-   **Find Action Items**

-   **Continue writing...**

These preset prompts represent a sampling of the fundamental
"transformation operations" that provide the most value for the most
people. The same prompts are also accessible in Grammarly, the editing
extension that assists you with wording wherever you type, as well as
browser extensions like MaxMe.ai, which appears to have copied Notion's
interface down to the icons that accompany each prompt.

![A screenshot of a phone Description automatically
generated](./book_media/media/image20.png){width="2.1319444444444446in"
height="3.1875in"}![A screenshot of a computer Description automatically
generated](./book_media/media/image21.png){width="2.5256944444444445in"
height="2.3118055555555554in"}

Preset commands in Grammarly (left) and MaxAi.me (right)

However, these basic prompts only scratch the surface of what's possible
once you master the true power of GPTs to transform base inputs into
precious metals.

Let's begin with my personal favorite -- the workhorse of AI-assisted
writing -- **Improve writing.**

### Improve Writing/Fix Spelling & Grammar

**Improve writing** restructures sentences, fixes spelling and grammar,
clarifies meaning, and enhances flow, whereas its sister prompt, **Fix
spelling & grammar**, makes fewer sweeping changes to your word choice,
only correcting what is grammatically incorrect.

Both of these prompts save time when correcting messy transcripts or
hasty rough drafts. But take care to check the outputs against the
originals to make sure that the "improvements" align with the speaker's
intent.

After every NotionAI command, you have the ability to review the output
and decide whether you want to replace the highlighted text, insert it
below, or discard it altogether. With **Improve writing,** I usually opt
to "insert below," while retaining the original as a reference to make
sure that no crucial meaning was lost, or intent altered. When running
**Fix spelling & grammar**, I usually just replace the old, typo-ridden
sentence with the new one because of its more cautious approach.

### Simplify Language

The **Simplify language** prompt is useful when you need help making
your writing less wordy and pretentious. It can also take a
jargon-filled block of text and make it more clear to a layperson.

### **Change Tone**

The **Change tone** prompt branches into five different options:

-   **Friendly**

-   **Casual**

-   **Professional**

-   **Straightforward**

-   **Confident**

These prompts have been engineered to be most useful to the most people.
However, they are also prone to exaggeration. Think of them as
suggestions -- not wholesale replacements of your own writing -- lest
your coworkers start to think an imposter is writing your
communications. In Chapter 11, I will discuss how to match a *specific*
tone based on your own sample material -- i.e., training AI to write in
your own voice -- without it coming off like a parody of the style you
are mimicking.

### Summarize

The **Summarize** prompt can help you create an overview of a page or
article in seconds. The longer the "source," the more details it will
condense. Summary outputs are capped at a certain point, so if you want
a more detailed summary, it's better to summarize in smaller chunks, and
then combine the summaries together.

### Make Shorter/Longer

While the **Summarize** prompt compresses the key points of a longer
text, **Make shorter** simply shaves away some extra words and tightens
up your language.

**Make longer** does the opposite -- adding details and length. The
danger of **Make longer** is that it must extrapolate based on its
training data, rather than your own source material. Use it sparingly.

### Find Action Items

The **Find action items** prompt is a subset of a whole family of
"extract" prompts, in which you can locate key information from a larger
volume of text.

This prompt is particularly useful when compiling to-do lists from
scattered notes or a transcript of a meeting in which no one was taking
notes. Several companies now offer subscription to automate the process
of recording, transcribing, and processing your transcript into
actionable notes. However, with just a few extra clicks and a
well-worded prompt, you can create your own custom-formatted meeting
notes for free using Notion or Claude.

## The Transformation Operation Station

For all of the above prompts, it's easy enough to reverse engineer the
prompts underlying Notion's AI interface within a chat console like
ChatGPT or Claude. In most cases, you can just use the words of the
operation, followed by a colon and the source material in quotes, like
this:

-   Improve the writing of this passage: "\<\>"

-   Summarize this: "\<insert source material\>"

-   Explain this: "\<\>"

These short commands carry enough of an "aura of meaning" to deliver the
desired output. However, you can increase the value of your
transformation operations by adding specific context and formatting
requirements. For example:

![](./book_media/media/image23.svg){width="4.5in"
height="1.3159722222222223in"}

Beyond Notion's preset prompts, we can explore a variety of other
transformation operations that come in handy in the writing process.
Each of the examples I've chosen below corresponds to a miniature job to
be done for the AI-assisted writer. This list is not meant to be
exhaustive. I have only included the operations that I use myself and
have found valuable or time-saving in some dimension. **NOTE:** All of
the following examples depend on the addition of source material after
the prompt.

**Paraphrase** --- Condenses and rewrites external material while
preserving meaning and citing original author. Useful for distilling or
citing research; quoting someone concisely.

**Example:** "Paraphrase this research paper, preserving the key
statistics and simplifying the academic language to make it more
accessible to a general audience."

**Reorganization** --- Structures disorganized content into outlines
with logical flow. Useful for bringing order to chaotic rough drafts and
scattered notes, identifying key themes and narrative arc, and
extracting section headers, and bullet points.

**Example:** "Help me reorganize ideas and create an outline. The
following notes contain a brainstorm for a potential blog post. Please
read through the notes and draft an outline for the blog post,
structuring the information in a logical order with an introduction,
body section headers, and conclusion. Ensure the outline presents a
coherent narrative flow and groups related ideas together. Use bullet
points to break down the content within each section."

**Proceduralization** --- Transforms process descriptions or video
walkthroughs into structured, step-by-step instructions. Useful for
developing standard operating procedures, troubleshooting guides, and
onboarding processes.

**Example:** "Please develop a standard operating procedure from the
following transcript of a process walkthrough video. Create a numbered,
step-by-step checklist with clear instructions that someone could follow
to replicate the process."

**Personification/Imitation** --- Mimics a specific writer's voice and
style. Useful for ghostwriting or maintaining brand voice.

**Example:** Please rewrite the following passage in the style of Hunter
S. Thompson.

**Transition** --- Smooths connections between ideas in a text. Useful
for bridging paragraphs, connecting concepts, establishing flow.

**Example:** Let's improve the transition between these two paragraphs:

> \[First paragraph\]
>
> \<improve transition\>
>
> \[Second paragraph\]

**Combination** --- Merges separate content together by removing
redundancy. Useful for integrating drafts, collapsing sections,
synthesizing sources.

**Example:** Please combine the following two passages into one
integrated version, eliminating any repetitive or redundant information
across both sources. Ensure all key details are preserved, and the tone
and style remain consistent. Rewrite any awkward transitions or overlaps
between the sources.

**Songify/Sonnetize** --- Turns your words into a lyrical or poetic
form. Useful for sea shanties, sonnets, limericks and impressing your
romantic prospects.

**Example:** Rewrite this section in the style of a Shakespearean
sonnet.

This broad overview of transformation operations only begins to catalog
the numerous ways you can "reprogram" text with simple, transformative
prompts. Indeed, if you consider the nature of natural language
programming, you will see that *every* word functions as an operator on
every other word -- altering their weight, their texture, and their
meaning.

These fundamental operations, combined with the strategies outlined in
the previous chapter, provide the essential toolkit to begin your own
creative journey with AI. I suggest starting with Notion's free version,
which offers a daily quota of AI prompts. For those ready to dive
deeper, a \$20 monthly subscription to NotionAI grants unlimited access
to these transformative commands. As we progress, we'll leverage these
prompting skills for increasingly intricate tasks, thereby enhancing our
"mechanical sympathy" with practical experience.

Though best known for his scientific achievements and the invention of
calculus, Isaac Newton also dabbled in alchemy. But while Newton failed
to find the mystical philosopher's stone, he made great strides in
chemistry and physics in the process. In a similar vein, failed attempts
at creative prompting can help you to refine your approach. Through
trial and error -- toil and transformation -- AI brings you closer to
realizing the ancient alchemical dream of turning simple inputs into
rich, expressive content.

## Try it Now:

-   Sign up for a free Notion account at <https://notion.so>.

-   Write about a topic you've been thinking about,
    stream-of-consciousness style -- don't worry about typos or
    imperfect grammar. Embrace the imperfection.

-   Now apply some different preset prompts like **Improve writing** to
    your "free write."

-   Lastly, try some of your own custom prompts -- both on highlighted
    text, and within a page of your own source material.

Part 2

The AI-Powered Content Engine

[Chapter 4]{.underline}

[]{#_Toc152566400 .anchor}THE TaaS REVOLUTION

Then they said, "Come, let us build ourselves a city, with a tower that
reaches to the heavens, so that we may make a name for ourselves;
otherwise we will be scattered over the face of the whole earth."

-- Genesis, chapter 11

In the biblical account, the Tower of Babel was an edifice of human
pride. It was erected with the ambition to reach the heavens and "make a
name for the builders," but this unity of purpose was fractured by a
divine intervention that confounded their language, leaving the tower as
a testament to their scattered aspirations. In a similar vein, today's
digital landscape mirrors the fragmentation of Babel. Instead of a
physical tower, we have constructed vast repositories of digital
content. The billions of hours of podcast recordings, videos, voice
notes, and meetings captured each day form a virtual monument to human
thought (and a fair amount of hubris). And like the ancient tower, our
auditory collection teeters on the brink of incomprehensibility, with
the vast majority of data scattered across cloud storage drives and
servers.

However, we now have the tools to bring order to this chaos as AI
transcription services begin to decode this mass of scrambled chatter
into a single format accessible to all: text.

Transcription as a Service (TaaS) has undergone a mini-revolution in
recent years thanks to advances in automated speech recognition. In the
early 2010s, researchers began using neural networks and larger datasets
to enhance accuracy. The advent of transformer architectures, such as
GPT-3, has further enhanced this capability through sophisticated
context modeling, enabling AI to predict words more accurately. The
quality keeps getting better, even as the cost plunges, in true Moore's
Law fashion.[^1]

In the past, although computer-generated transcription was a functional
tool, it required significant effort to correct numerous errors, add
proper punctuation, and refine the raw, imperfect output of human
speech. In 2016, when I first began working with speech recognition
tools, a mediocre AI-generated transcript cost me around \$15. Today you
generate a much more accurate version for pennies. Quality transcription
used to be reserved for television closed captioning, courtroom
dialogue, depositions, and other matters of importance where a clear
record was needed for a specific job. Now, it's everywhere:

-   Instagram and YouTube generate automatic transcripts to caption
    their videos, at no cost to users, as do many podcast recording,
    editing, and publishing platforms.

-   Slack adds a transcript to any audio or video message you send to
    your coworkers.

-   Zoom's meeting assistant "takes notes" while you talk, based on
    real-time transcription taking place.

By itself, a transcript functions as a useful reference for what was
said in a conversation. However, the real untapped potential lies in the
combination of AI-powered *transcription* with LLM *transformation*.
Vast troves of audio content can now be unlocked and repurposed,
changing the way people do business in a variety of industries:

-   Conference calls into actionable tasks...

-   Corporate training sessions into manuals...

-   Educational lectures into study notes...

-   Screenshare videos into how-to guides...

-   Customer service calls into FAQ resources...

-   Medical dictations into patient records...

But the industry that will change the most will be that of content
creation and writing itself. The possibilities for repurposing are
endless:

-   Podcasts into engaging blog posts or articles

-   YouTube series into e-books or compiled narratives

-   Webinars into instructional e-books or lead magnets

-   Interviews into biographical features

-   Improv comedy into scripted sketches

-   Livestreams into serialized content

-   Speeches into opinion pieces or editorials

Celebrity podcasters like Tim Ferriss and Guy Raz were early here --
turning their most popular episodes into best-selling books. Ferriss's
*Tools of Titans*, for example, condensed insights from over 100 podcast
interviews with "world-class performers" into an 800-page tome. The book
debuted in 2016 as the #1 New York Times bestseller.

Around the same time, I sold my first manuscript to a publisher. It,
too, was a compilation of interviews that I had edited for a client of
mine with a radio show. Despite the anthology format, the book became
one of the publisher's best-sellers, selling 25,000 copies since 2017
and counting.

For those looking to repurpose and extract value from their growing
libraries of audio content, AI-generated transcripts provide the perfect
"source material" for LLMs like Claude to repurpose into higher-value
content. With a transcript, all your ideas are on the page. Your task
becomes one of commanding AI to distill maximum meaning from that page
and transform noisy speech into polished prose.

## **Generating a Raw Transcript**

The first step in this process is to generate a high-quality transcript
of your audio.

For podcasters, the best-in-class recording software
[Riverside.fm](http://Riverside.fm) offers quality transcription, as
does the best-in-class editing software, Descript. However, in my
experience, these tools provide good but not great transcription
compared to services that specialize in transcription only, like
[Otter.ai](http://Otter.ai) and [Rev.com](http://Rev.com). I use Otter
because it offers the best accuracy-to-price ratio for my needs, and
also integrates with Zoom -- adding a note-taking "assistant" to my
meetings.

[Rev.ai](http://Rev.ai), an offshoot of Rev.com, offers the cheapest
bulk transcription for just 2 cents per minute -- useful when you want
something quick, cheap, and high-quality for a one-off job -- without
the hassle of a monthly subscription.

Finally, OpenAI licenses its in-house Automatic Speech Recognition (ASR)
technology, Whisper, to several products that integrate transcription
into their products. ChatGPT, for example, recently enabled "voice
mode," powered by Whisper, which lets you talk into your phone's
microphone rather than type in the chat box. The transcription quality
inside the ChatGPT app is excellent. It puts punctuation in the right
place and even papers over errors and filler words in your speech.
Because OpenAI grants API access to anyone looking to develop on top of
Whisper, you can build your own custom transcription tools that cost a
fraction of even the cheapest paid transcription services. The latest
version of Whisper charges less than 1/10th of a cent per minute.

Most of these services claim around 95% accuracy. Whisper claims to have
achieved 98.5%, which is believable based on the quality of voice mode
within ChatGPT. With these rates, you might expect that human
transcription would be a thing of the past. On the contrary, customers
are now paying a premium for humans to provide the last 2-3% of accuracy
that the machines miss. Once again, human + AI beats either one alone.

But correcting basic errors is only one way that a human can increase
the value of a raw AI-generated transcript. I predict that a whole new
industry will emerge based on the creative transformation and
"upcycling" of ideas from the heaps of audio content that have been
accumulating. This ability to transform spoken words into text is
crucial in today's information landscape, given that it's often easier
to articulate ideas aloud than to write them down, yet written content
remains the preferred medium for consumption.

We begin this upcycling process by liberating your ideas from audio into
editable text. But capturing this raw source text is just the first step
in our alchemical process. Next, we must learn to wield AI commands for
refining and increasing its value -- starting with the simple but
powerful use case of the sweetened, condensed transcript.

## Try it Now:

-   Sign up for a free account at [Otter.ai](http://Otter.ai).

-   Download the Otter phone app and widget.

-   Take a walk while recording yourself riffing "stream of
    consciousness" on something you've been thinking about. Review the
    transcript and see how accurate it was.

-   Alternatively, download the ChatGPT app and enable "voice mode" by
    pressing the headphones button ðŸŽ§ to the right of the chat box. Have
    a conversation with your new AI assistant and then review the
    quality of the transcript.

[Chapter 5]{.underline}

[]{#_Toc152566401 .anchor}POLISHING

Sweetened Condensed Transcripts

"Omit Surplus Words."

*--Â *Plain English for Lawyers

The harshest critique someone could make of this book is that it should
have been an article. In a world where you can generate mountains of
text with a few keystrokes, we must resist the temptation to be
long-winded. Even before ChatGPT, many books could have been written as
long-form essays. Many articles should have been blog posts. Many blog
posts should have been tweets. And most tweets should have been...
skipped.

Likewise, most hour-long conversation transcripts can be reduced by at
least half, without losing any meaning once you remove filler words and
rework rambling sentences. Only the most eloquent among us speak the
same way we're taught to write -- with complete sentences, concise
logic, and impeccable grammar.

*Most of us talk more, like, well -- you know\... less polished. And
this is the thing. No one wants to read prose like this italicized
paragraph. Sentence fragments. While you're speaking, a dangling
modifier is introduced into the conversation.*

There are better ways to convey the essential points than a 100%
accurate, verbatim transcript.

Prior to the release of AI tools, I had an effective system for refining
rough podcast transcripts. It took about three hours to scrub the "ums"
and "uhs" and pare down the fluff by hand. Now, with NotionAI's magical
**Improve writing** wand, I can transform messy speech into clear
writing in minutes. And the output is *better* than what I used to get
when doing it the old-fashioned way.

## Waving the Magic Wand

The full power of the Improve writing wand is best illustrated by an
example. To generate the text below, I opened MacOS's native dictation
software[^2] and started rambling:

> All right so this is just me talking and you know the thing is when
> you're talking like this speaking out loud and your spit balling ideas
> trying to come up with sort of the core essence of what you want to
> say there is a challenge which is that your usual speech the way you
> talk to other people does Nova sound the same as if you were writing
> it out in advance writing an outline and then sitting down and editing
> it after the fact so you're gonna get a piece of transcript text
> that's not nearly as clear concise if you're just going to stream of
> consciousness do what you would get if you had actually planned it out
> in advance and written it right

Now, let's wave our magic wand and ðŸª„**Improve writing**:

> Okay, so this is just me talking and brainstorming ideas. One
> challenge I face is that my spoken words are often not as clear and
> concise as they would be if I had written them out in advance and
> edited them afterwards. When you speak spontaneously, it can be
> difficult to articulate your thoughts as effectively as you would in a
> written format. As a result, the transcript of this conversation may
> not be as polished as a carefully crafted piece of writing.

Better, but still a bit wordy. Let's **Make it shorter:**

> When speaking spontaneously and brainstorming ideas, it can be
> challenging to capture the core essence of what you want to say. The
> resulting transcript may not be as clear and concise as a carefully
> planned and edited piece of writing.

Now we're talking. Or, rather, transcribing...

The downside of the magic wand is that it can be too aggressive in
correction -- making the words sound foreign to the person who spoke or
wrote them.

**Fix spelling & grammar** takes a more cautious approach, preserving
meaning despite leaving in some errors. Thus, you're faced with a
trade-off: **Improve writing** enhances clarity but may lose accuracy.
**Fix spelling & grammar** retains accuracy but leaves in defects.

When accuracy is more important, I will run both prompts -- **Improve
writing** and **Fix spelling & grammar** -- on an entire transcript. I
then create two or even three side-by-side columns on a Notion page,
containing the original and each enhanced version. This allows me to
compare one section at a time and incorporate the best aspects from all
versions while ensuring that the prompts didn't alter the meaning of the
speaker.

### The Two-Column Method

**ORIGINAL** All right so this is just me talking and you know the thing
is when you're talking like this speaking out loud and your spit balling
ideas trying to come up with sort of the core essence of what you want
to say there is a challenge which is that your usual speech the way you
talk to other people does Nova sound the same as if you were writing it
out in advance writing an outline and then sitting down and editing it
after the fact so you're gonna get a piece of transcript text that's not
nearly as clear concise if you're just going to stream of consciousness

**ENHANCED** Okay, so this is just me talking and brainstorming ideas.
One challenge I face is that my spoken words are often not as clear and
concise as they would be if I had written them out in advance and edited
them afterwards. When you speak spontaneously, it can be difficult to
articulate your thoughts as effectively as you would in a written
format. As a result, the transcript of this conversation may not be as
polished as a carefully crafted piece of writing.

The "*Two-Column Method" preserves the original on the left so you can
cross-reference it against the text on the right.*

**Improve writing** works best on blocks of text of around 250-300
words. **Fix spelling & grammar** can handle 500 words or more, but when
the text exceeds that limit, the AI will not only correct errors but
also start compressing important details.

When accuracy matters most, like preserving exact quotes as a
journalist, use **Fix spelling & grammar**. **Improve writing** is fine
when dictating first drafts. With podcast transcripts, I reserve
**Improve writing** for the host, while employing **Fix spelling &
grammar** for guests' words. Most guests do not mind having their words
altered if it makes them sound more articulate, but I still err on the
side of caution. As AI advances, you will be able to train AI and
"adjust the dials" to the right balance for your use case and perform
these operations on an entire long document in one fell swoop.

## Improving Transcript Structure

Notion's preset prompts are tailor-made for polishing individual
sections of a transcript, but if you want to enhance the conciseness,
readability, and logical flow of ideas at a broader level, it's better
to use the chat console version of Claude.

Within the chat box, you will attach (or copy and paste) the full
transcript, along with some basic context on the topic and
task:![](./book_media/media/image25.svg){width="4.5in"
height="3.4895833333333335in"}

You might be able to delete 20-30% of the transcript through these
changes alone.

If you are in the habit of introducing your guest with a bio, consider
repurposing that text as a short, italicized preface to the chapter
rather than something that is spoken by the host:

![](./book_media/media/image27.svg){width="4.5in"
height="1.1819444444444445in"}

You can ask Claude to look for sections that might benefit from being
relocated to improve the flow of the manuscript. Identify any redundant
sections and choose the best-worded version to keep, deleting the other
section or moving the selected section to where it fits best in the
manuscript.

![](./book_media/media/image29.svg){width="4.5in"
height="1.3159722222222223in"}

The standards for transcripts that you publish on your website or
alongside "show notes" are lower than they would be for an interview
being printed in, say, *Rolling Stone* or *New York Magazine*. However,
these small changes can have a big impact on the reader's experience.
For example, if you publish your podcast on Substack, a polished
transcript can serve as exclusive content for paid subscribers: give the
audio away for free and save the sweetened condensed version for your
biggest fans.

## Pull Quotes & Other Flourishes

As a final flourish, you can use a simple extraction prompt to find
attention-grabbing quotes, that you can format to stand out from the
main text:

![](./book_media/media/image31.svg){width="4.5in"
height="4.404861111111111in"}

With this prompt, we are beginning to extract higher-value assets from
our source material beyond the verbatim record of the conversation.
These "pull quotes" will draw readers' attention to key points and break
up the text to make it more readable.

In the next chapter, we will build on this basic idea of mining
transcripts for gems -- exploring one of the simplest yet most powerful
applications of AI. We will generate keyword-optimized podcast show
notes and metadata from our edited transcript. Optimizing show notes for
search engines distills your key takeaways into bite-sized insights.
This makes it easier for people to find and apply the solutions shared
in your content. As we venture into the realm of optimized show notes
and metadata, we bridge the gap between content creation and content
discovery. In essence, we not only tell the story but also ensure it
reaches those who seek it.

## Try it Now:

-   Take your AI-generated transcript from the previous chapter and
    copy-paste it into a Notion page.

-   Run the **Improve writing** and **Fix spelling & grammar** prompts
    on a block of rough text.

-   Insert the AI-edited text below the original and review what changes
    were made. Did Notion AI fix errors while preserving meaning? Where
    did it make mistakes and "overcorrect"?

# 

[Chapter 6]{.underline}

[]{#_Toc152566402 .anchor}SEO SHOW NOTES

(In 7 Steps)

"Content is fire. Social media is gasoline."

--Â Jay Baer, digital marketing strategist and author

AI-*generated* content gets a bad rap. And for good reason. I generated
a hypothetical social media post with a one-line prompt based on the
contents of the chapter you are about to read:

![](./book_media/media/image33.svg){width="4.5in"
height="1.1916666666666667in"}

Here's what it gave me:

> "ðŸ”— Show notes are important but tedious. New AI tools promise to
> automate them. But fully automated show notes are generic. The key is
> collaboration. This chapter explains how to repurpose transcripts into
> optimized show notes with AI's help. Follow for more AI writing tips!
> #ai #contentcreation #podcasting"

Is it descriptive? Sure. Is it accurate? Close enough. Does it make you
want to read on? I'm guessing that if you came across it on Facebook or
Twitter, you wouldn't stop your doom-scroll for long enough to read it,
let alone "follow" or click through to an external link. Why not?
Because it feels stale and boring.

-   Generic hashtags? Check.

-   Random link emoji? Check.

-   Vague clichÃ©s like "The key is collaboration"? Yawn. Check.

When I first realized how NotionAI could help me polish transcript
content, I went in search of a tool to simplify the preparation of
podcast "show notes." I found several options. Capsho, for example, lets
you upload your audio and then spits out a series of AI-generated assets
based on the transcript. These assets include:

-   Titles/Email subject lines

-   Opening hooks or "honey pots" to captivate the reader

-   Timestamped outline summaries

-   Teaser descriptions

-   "Potent Quotables" (similar to the "pull quotes" extracted in the
    previous chapter)

Their pro plan also offers customized formatting of your assets for
social media, following best practices for each platform. For Instagram
and TikTok, for example, the outputs are programmed to contain relevant
hashtags for keywords. For Twitter posts, the length is automatically
limited to 280 characters. And for LinkedIn, the underlying prompt
probably includes a template for crafting the perfect humblebrag.

Capsho's outputs helped me get the creative juices flowing, but in the
end, I canceled my free trial. Why? Because I found that I could get
better, more customizable results by following my own multi-step
process.

The process I present here for generating show notes provides a
foundation for repurposing transcripts into other formats like blog
posts and, eventually, whole books. As you read this chapter, take note
of the sequence of prompts - the "order of operations." There is a logic
to doing certain things first, leveraging AI's tendency to do its best
"thinking" in discrete, logical steps. Within each step, you will
provide gentle nudges to steer the AI to your destination. We will apply
this same basic chain of prompts to create ever-longer and more complex
content from podcast transcripts. As we zoom out from this simple use
case of show notes, we will discover the same steps repeating at each
level of complexity, like a fractal pattern where each small part
mirrors the structure of the whole.

## Brilliant Show Notes in 7 Steps: Chain-of-Thought Revisited

While the previous chapter leaned on Notion AI to polish the rough
AI-generated podcasts, this process for generating SEO show notes is
optimized through a direct conversation with our trusty AI assistant,
Claude. The chat format provides flexibility and allows for course
correction due to the ongoing, unfolding nature of the conversation.

### Prompt #1: Getting Your Bearings

To start this exercise, you'll need to have a transcript handy (on a
Notion page or in a Word or Google Doc). Using Claude, attach the
transcript in the prompt window and issue these instructions:

![](./book_media/media/image35.svg){width="4.5in"
height="2.8986111111111112in"}

Telling Claude to "take a deep breath" here, like instructing it to
"think step-by-step," primes the model for better responses to tasks
that involve multiple steps. Without these instructions, Claude is like
an anxious sprinter who false starts before the gun goes off --
generating a lot of unwanted text. Hard to believe? It was for me too.
If you need convincing, try it. Run the same prompt without the words
and see how the output changes. Tweaking instructions can be helpful as
you develop your mechanical sympathy and intuition about prompting.

After this initial prompt, Claude will affirm that it has read the
transcript and may provide some broad notes on what it learned about the
key points. This output serves as a kind of sense check. We will not use
this response, but if something is way off, we can stop and correct it.

From here, we begin to map out the contents of our source material at a
high level:

### Prompt #2: Timestamped Outline

![](./book_media/media/image37.svg){width="4.5in" height="1.50625in"}

Copy the transcript outline produced by Claude and paste it into the
same document that contains your transcript and show notes --Â whether in
Notion or elsewhere. This provides you with a keyword-rich "map" to the
episode, so listeners can decide whether to tune in or skip to a
specific segment.[^3] If you are publishing the entire transcript with
your show notes, you can re-use the outline as guideposts and section
headers within the transcript itself.

## SEO in the AI Age

Now, with your map of the territory, you are ready to home in on the
*main* *point* -- the single biggest takeaway you would want readers or
listeners to glean from the episode. All of the assets you will create
from this point forward will hinge on the proper identification of the
main idea. For example, you can't write a good title or description
before you decide what the episode is *about*. After uploading your
audio, the first thing Capsho does is suggest three potential
characterizations of the main theme of your episode. You pick one, on
which it bases the outputs. Our next prompt will mimic this process, and
use the context we've already established to suggest several options for
the main idea[^4]:

### **Prompt #3: Main Idea -- Suggestion**

![](./book_media/media/image39.svg){width="4.5in"
height="1.601388888888889in"}

With this prompt, we're gearing Claude to generate content that's useful
and SEO-friendly. SEO, or Search Engine Optimization, is all about
making your content more visible and attractive to search engines like
Google. Google's SEO guidelines have long favored content exhibiting
qualities of "E-A-T"-- short for expertise, authority, and
trustworthiness. Now, they are adding an extra "E" for *experience --*
seeking content that demonstrates real-world knowledge and credibility
over generic AI-generated content. This change in the search algorithm
represents an opportunity for creators with *true* subject matter
expertise to stand out. Those who exemplify depth of knowledge will be
rewarded in search rankings, while those who regurgitate basic
information contained in the training data will be punished. Your show
notes and description are an ideal place to emphasize experience and
credentials -- both your own and those of your guests.

With these points in mind, you can mix and match the suggestions for the
main idea, or rewrite it to fit your understanding:

### **Prompt #4: Main Idea -- Refining, Pt. 1**

![](./book_media/media/image41.svg){width="4.5in" height="1.125in"}

Or...

![](./book_media/media/image43.svg){width="4.5in" height="1.125in"}

Now, your main concept functions as a kind of one-line description of
the episode. But most podcasting platforms, as well as YouTube, allow
more than just a one-line description to help people find your content.
After the title, the description field is the best place to hook your
audience and load up on SEO-optimized keywords so that your content has
the best chance of being discovered or recommended to your ideal viewers
and listeners.

People often think of SEO as a zero-sum game, with fierce competition
for top rankings on scarce online real estate (search results). I find
it more helpful to think of SEO as a way to connect real people to real
solutions and the information they are seeking.

What's the point of trying to trick people into clicking your link only
to find that it doesn't contain what they're looking for? Instead, focus
on compelling yet accurate titles and descriptions that reflect your
niche expertise. Titles should avoid common tropes. Balance keywords
with natural language and conversational tone. Hook readers with
curiosity and a message about specific benefits to them. Descriptions
should showcase your experience and authority.

Before you set out to create content, research what questions people are
asking around your niche using tools like Google Trends, Ahrefs, and
AnswerThePublic, then tailor the content to address those knowledge
gaps. Weave in personal anecdotes or your origin story related to the
niche, and back up your claims supporting the main idea with evidence
and external links. You must first extract these key building blocks of
content from your transcript before you can write solid SEO titles and
descriptions.

Our next prompt will kill two birds with one stone, helping you identify
quotes that will both bolster the authority of your content, and serve
as the basis for shorter standalone "microcontent" that can be shared
alongside your podcast:

### **Prompt #5: Potent Quotables**

![](./book_media/media/image45.svg){width="4.5in"
height="3.2416666666666667in"}

These timestamped quotes make it easy to clip snackable video snippets
or produce quote graphics to share across social media platforms.
Finally, if you are writing a longer blog post summary of the episode,
these quotes will also serve as valuable assets to bring the text to
life, with your guest's own voice -- breaking up the monotony of the
summary.

Next, ask Claude to identify a list of links and resources mentioned in
the transcript with this prompt:

### **Prompt #6: Links and Resources** 

![](./book_media/media/image47.svg){width="4.5in"
height="1.2201388888888889in"}

This links section can enhance the trustworthiness of your post. While
AI tools like Claude are unable to provide up-to-date links, ChatGPT is
now integrated with Bing to access current web pages and format pages as
clickable links, pulling from live web search data. Still, it remains
wise to verify these links to maintain the integrity of your content.

At last, you are ready to prompt Claude for title and description
suggestions -- the capstone of your show notes. These are the most
important fields because they influence SEO the most and are what most
people will see first in deciding whether to read or listen.

### Prompt #7: Title & Description

![](./book_media/media/image49.svg){width="4.5in"
height="1.945138888888889in"}

Here, the requested length instruction is based on YouTube best
practices, but this length works for podcast descriptions as well.

If you already have standard formatting for your episode titles or
descriptions, you can attach additional examples along with your
instructions:

![](./book_media/media/image51.svg){width="4.5in"
height="1.6590277777777778in"}

Your title and description function as the sales pitch for the rest of
your piece, so after reviewing the suggestions, spend some time
iterating with Claude, or just rework the outputs with your own ideas.
Remember that the AI's responses should be viewed as first drafts. This
is true whether you are working directly with Claude, or with a tool
designed to give you specific assets.

There are already dozens of tools out there to help you generate SEO
content based on just a few keywords. **Some are even good.** The beauty
of this process, using the chat console, however, is that you remain in
the driver's seat throughout -- refining outputs at each stage and
training the model with your feedback.

Rather than asking AI to generate your assets in a single prompt, you
will get much better results by overseeing its output in this way. When
your competition can churn out masses of generic content with AI, you
can't compete on the quantity of output or keyword loading alone. To win
the SEO game, you'll need a quantity of *quality --* a large volume of
well-organized long-form content based on your expertise and written in
your voice. That's how you'll earn your readers' trust (and Google's).
With your AI-powered content engine fired up, let's remain in the
driver's seat see where this hotrod can take us.

## Try it Now:

-   Provide Claude with a transcript, along with single prompt to
    generate a title and show notes for the episode.

-   Then, start a new dialogue and run through the sequence of prompts
    in this step -- working towards the main idea before writing your
    title and description.

-   Compare the two. Which one is more compelling?

# 

Part 3

Becoming a "CODER"

[Chapter 7]{.underline}

[]{#_Toc152566403 .anchor}OF PYRAMIDS & DIAMONDS

Have We Reached "Peak Content"?

"Content is king, but context is God."

--Â Gary Vaynerchuk

In a world where content is king, Gary Vaynerchuk -- aka Gary "Vee" --
reigns supreme with his miniature media empire. He commands the
attention of over 44 million followers across all of his social media
accounts.

Vaynerchuk has built his platform atop his trademark "Reverse Content
Pyramid," which starts with a substantial, single piece of content --
referred to as "pillar content" -- such as a podcast, a keynote speech,
or a detailed YouTube video, positioned at the top of this inverted
pyramid. From this pillar content, he extracts smaller, more digestible
pieces, known as "microcontent." Microcontent includes elements like
video clips, memorable quotes, short blog posts, and memes. These brief,
attention-grabbing pieces are tailor-made for the short attention spans
of people on social media and this approach has proven effective --
generating a remarkable total of over 35 million views spanning
Instagram, YouTube, Facebook, Twitter, LinkedIn, TikTok, Snapchat, and
Spotify.

The success of this approach is undeniable, spawning legions of copycats
all striving to replicate his blueprint. Everybody wants to be Gary Vee.

![A black and white triangle with icons Description automatically
generated](./book_media/media/image52.png){width="4.14387467191601in"
height="4.395833333333333in"}

In the last chapter, we learned how to condense long transcripts into
more digestible short-form content, such as show notes, podcast
summaries, and social media snippets. Similarly, we can create dynamic
Instagram Reels and TikToks using the same pillar content. Despite this
strategy's effectiveness in garnering attention, it poses a critical
question:

Are we making a contribution, or just contributing to the noise?

The surge of content is already here. The floodgates will open further
as AI continues to level the playing field and make it easier to
repurpose a single podcast or article into dozens of smaller pieces. We
risk drowning in a rising tide of low-value content that delivers more
noise than signal -- more warmed-over platitudes than genuine insights.

## The Case for Long Form: Inverting the Reverse Content Pyramid

While the Reverse Content Pyramid excels in generating views, another
approach focuses on converging multiple ideas into a cohesive,
substantial composition. In this strategy, you *aggregate* smaller
content pieces as the building blocks for more comprehensive articles,
chapters, and books.

In this upright pyramid model, we still begin with pillar content such
as in-depth videos, articles, or podcasts. These pillars, developed over
time, support the creation of enduring long-form content, which
establishes your expertise above the fray of the social media
free-for-all. Over time, these pillars mature and grow until you reach
the pinnacle of thought leadership: a book that embodies your unique
perspective and knowledge.

![A black and white triangle with text Description automatically
generated](./book_media/media/image53.png){width="4.259288057742782in"
height="4.423611111111111in"}

A book is a tangible item that readers can hold, feel its weight,
immerse themselves in, revisit, and share with others. A book stands out
in the physical world, whether it's displayed in an airport kiosk or a
bookstore window, enticing passersby to step into your world. Even a
self-published book or digital book can be as valuable as one published
by a traditional publishing house if it solves a real problem for a
specific audience.

My experience with long-form content has resulted in partnerships with
publishing houses and the sale of over 50,000 copies. While the
royalties are not enough to supplant a full-time income, my
self-published titles earn me a steady annuity through Amazon's Kindle
Direct Press platform. Moreover, my articles continue to be read, even
years after their publication, because I have focused on creating
content that remains relevant over time rather than chasing trends. Only
those who offer depth and insight will stand out in a landscape where
superficial content is commonplace.

![A graph on a white background Description automatically
generated](./book_media/media/image54.png){width="4.625in"
height="2.2525459317585304in"}

Repurposing content upwards does not stop you from leveraging short-form
social media. Instead, it can give those activities more purpose.
Imagine your content strategy not merely as a V-shaped funnel but as a
diamond, where ideas flow both upwards from short-form to long-form,
content and downwards -- breaking longform back down into bite-sized
pieces. This dual approach ensures a broader reach and fine-tunes your
message, testing smaller ideas that have the potential to expand into
larger projects.

![A diagram of a book Description automatically generated with medium
confidence](./book_media/media/image55.png){width="4.5in"
height="7.04375in"}

## **The CODER Framework: Crafting Your Content Diamond**

In flipping Gary Vee's reverse pyramid back into an upwards-pointing
pyramid, I'm aligning with a core principle in this book: AI is most
powerful as a tool to refine raw inputs. It's a *transformative* process
of reworking and elevating your existing content and ideas -- those
"trapped" in your head or in an archive of content like a folder of
notes or transcripts from a podcast.

As you work your way up and down the content *distribution* diamond,
there is a second diamond visual -- flipped horizontally -- that can
guide you in content *creation*. Tiago Forte, best-selling author of
*Building a Second Brain*, has a four-step "CODE" framework that aligns
with this diamond shape. Forte simplifies the creative process into four
stages: **Capture, Organize, Distill,** and **Express**. This acronym
represents a whole philosophy around content creation. "**Capture*"
***and "**Organize*" ***represent the initial expansive gathering and
structuring of your content. These initial "divergent" steps build up to
"**the point**" -- the crux of your message and the main idea from which
it all begins to converge. Next, you enter the "**Distill*" ***stage,
extracting the essential supporting points before reaching the
"**Express*" ***stage, where your ideas are articulated in their most
compelling form.

![A white diamond with black text Description automatically
generated](./book_media/media/image56.png){width="4.5in"
height="2.7784722222222222in"}

If you go back to the previous chapter, you will discern this
progression in the process we used to turn a transcript into final
promotional materials:

-   First, we **captured** ideas in the form of a podcast transcript.

-   Then we **organized** ideas in search of the main idea -- the Point.

-   Next, we **distilled** key details like quotes, links, and
    supporting points.

-   Lastly, we **expressed** the distilled ideas in the title,
    description, and marketing copy.

As we begin to construct longer and more complex forms of content, the
CODE framework scales with us in a fractal pattern. It's an iterative
loop that you'll travel repeatedly as you refine each layer of your
content, ensuring that each stage is a building block to a more
intricate and impactful whole. In the next stage of this journey, we
will apply the CODE framework to the process of turning a podcast into
an article. The final stage will involve writing entire chapters and,
eventually, books. Different formats, same progression: **Capture,
Organize, Distill, Express.**

I have added one final letter to Forte's acronym, R, for the
"**Refining"** phase. This is where we add the finishing touches,
polishing the diamond until it shines with clarity. Each of these
diamond schematics is powerful on its own. Together, they provide a
framework for the efficient *expression* of your ideas, followed by
efficient distribution across the full spectrum of platforms and media
-- from short-form social media snippets to long-form print books. In
following this methodology, you evolve from a writer into a **CODER** of
meaningful language -- a natural language programmer. You become a
commander of the page, bringing order, logic, and clarity to messy,
unstructured ideas in record time.

Let's now shift from theory to practice -- applying these principles
with a step-by-step process for transforming your "pillar content," like
podcasts, into polished, engaging articles. We begin with the first
phase of all creative processes: capturing your ideas in their raw form.

[Chapter 8]{.underline}

[]{#_Toc152566404 .anchor}CAPTURE

Treasure In, Treasure Out

"Garbage In, Garbage Out"

-- Old programming adage

"On two occasions I have been asked, "Pray, Mr. Babbage, if you put into
the machine wrong figures, will the right answers come out?"Â \... I am
not able rightly to apprehend the kind of confusion of ideas that could
provoke such a question."

-- â€ŠCharles Babbage,Â *Passages from the Life of a Philosopher*

How can you tell the difference between an article that was written by a
human and something churned out by AI in seconds? If there are typos,
it's probably of human origin. When it comes to the basic writing
mechanics and even certain stylistic elements, AI has gotten good.

How good? Let's put it this way. Joshua Lisec, one of the most talented
and sought-after ghostwriters of our generation,Â observes that AI is
already better than 95% of writers -- yes, even the good ones. In his
book, So Good They Call You a Fake, Lisec confronts the rise of
affordable AI tools that boast the ability to generate blog posts,
articles, or even entire books with a few clicks. Podcasting publishing
assistant Podium, for example, recently announced a beta program called
"PodBook" that promises to turn 20 podcast episodes into a full-length
book -- ready for you to edit -- in under 24 hours.

For writers to stand apart in this new landscape, Lisec's advice is
clear: you have to be "so. much. better. than a good, cheap, fast
content generator any schmuck can use over a few days to write, edit,
and publish the next great American novel."

Yet, Lisec also recognizes that while AI might be capable of producing a
high volume of passable content (with impeccable grammar), it is still
missing a certain "X factor." To illustrate his point, Lisec undertook
an experiment using various AI tools to write a hypothetical book
chapter. When prompted, the AI could only regurgitate the input Lisec
gave it -- a slightly reworded version of his prompt, padded with fluff.
Lisec then rephrased his prompt to inject more inner conflict, and the
AI invented a fictional struggle while still failing to add any
meaningful details or novel information.

Lisec concludes two things from his experiment: first, that the output
is only as good as the input, and second, that you cannot use AI to
write a book. I agree with the first part of his conclusion. Programmers
have a phrase for this: **Garbage in, Garbage out**. In other words,
flawed or nonsensical data inputs (**garbage in**) lead to nonsensical
outputs (**garbage out**). Thus, AI writing tools are only as effective
as the expertise and unique experience of the author using them.
However, I disagree with the assertion that you can't write a book with
AI. It all depends on how you use the word "with."

## AI "Sourcery" and t**he Importance of Quality Inputs**

To be sure, the gap between AI-generated and the very best
human-authored content remains significant. Though mechanically sound,
AI tools are mostly limited to the pool of congealed knowledge in their
training data -- a stale summation of word vectors. Think Wikipedia but
written by a robot. Great writing still requires inputs provided by a
knowledgeable creator who can weave them into a rich tapestry based on
subtle context that is not available to AI.

The missing variable in Lisec's experiment was not skill on his part as
a writer -- he's one of the best -- but rather the lack of *source
material* he gave the AI to work with. This takes us back to the art of
AI alchemy, or what I call "Sourcery': the transmutation of one's own
experiences and expertise into polished content. Sourcery begins with
mining the depths of your intellect for source material and then
refining it *with* AI's help.

Now, let's be clear: Lisec knows how important quality source material
to the writing process. When a professional ghostwriter sets out to
write a book for their client, where do they start? By interviewing
them. In this way, you capture the raw material -- the ore of original
thought. In fact, if Lisec senses that a prospective client doesn't have
anything meaningful to say, he won't agree to write their book -- no
matter how much money they offer him.

A professional ghostwriter's interviewing and writing talents can be
expensive, but you don't need a ghostwriter to help you capture the
thoughts and ideas that will become your source material. For example,
if you host a podcast, your accumulated archive represents a treasure
trove of content. The dynamic and spontaneous nature of conversation in
podcasts, with its ebb and flow of dialogue and spur-of-the-moment
ideas, captures the essence of authentic communication and idea
generation. Evolutionary biologist Matt Ridley has a term for this
synthesis: "Ideas Having Sex." The interplay of thoughts between the
interviewer and interviewee culminates in the birth of a newborn
perspective.

Therefore, as AI-assisted writers, we must adopt a new maxim to
emphasize the significance of high-quality inputs: **"Treasure In,
Treasure Out."** The richness of the material we feed into AI determines
the quality of content we craft. Starting with rich, authentic content
is key.

## What If I Don't Have a Podcast?

If you don't have a podcast, one simple yet powerful method for
generating source material is to take a walk with your phone and record
your thoughts and ideas. This act of speaking freely, perhaps while
meandering through a park or walking your neighborhood streets, can
capture a fresh stream of consciousness born of sunshine and outdoor
air. In the next few chapters, I will be using a 10-minute voice memo
that I recorded on a quick walk around the block using the
[Otter.ai](http://Otter.ai) transcription app on my phone.

You can also record a brainstorming session with a friend or colleague.
Use these conversation partners as a sounding board to spark new ideas
and sharpen your perspective.

Finally, if you can't find a willing human, you can start up a
conversation with ChatGPT in its new "voice mode." Start the
conversation by telling it to help you brainstorm. You can give it a
role, like an expert in the topic you're exploring, and request that it
prompt you with follow-up questions on the topic -- considering your
audience and objectives -- until you've covered everything you have to
say. The written record of the conversation will then serve as rich
source material for the next steps.

However, capturing these ideas is just the first step. This raw material
must be reorganized for maximum clarity and persuasion. Next, we begin
to give structure to our "skeleton" outline that will be fleshed out in
progressive stages. This process involves at least two windows:

-   A word processor, where the craft takes shape (I prefer Notion for
    its versatility).

-   An LLM chat console (Claude). While user-friendly AI writing tools
    like [Jasper.ai](http://jasper.ai/) offer a simplified interface,
    they come with constraints. Claude allows for deeper engagement with
    your source material.

In the upcoming chapters, you will learn to transform your source
material -- whether it's a transcript, a voice memo, a rough draft, a
"brain dump," or a set of disorganized notes -- into a polished
composition. While I have the most experience working with podcast
transcripts, the principles apply to any content source that contains
your perspective.

Our goal is not just to reformulate the input but to *improve* it.
Mastery over the "transformation operations" introduced earlier in this
book becomes crucial here. Grasping the correct order of these
operations is equally crucial for fine-tuning the desired outcome from
AI tools. As we saw in the example of generating show notes from a
transcript, AI-assisted writing is an iterative dance, relying on human
judgment at each step. First, we deconstruct the source material into
its constituent parts and then reconstruct it into targeted assets with
enhanced clarity and persuasiveness. Finally, the writing phase, which
includes strengthening, refining, and editing the draft, ensures the
finished product is nothing short of perfect, polished prose.

[Chapter 9]{.underline}

[]{#_Toc152566405 .anchor}ORGANIZE

Building Towards "the Point"

"For which of you, desiring to build a tower, does not first sit down
and count the cost, whether he has enough to complete it? Otherwise,
when he has laid a foundation and is not able to finish, all who see it
begin to mock him, saying, 'This man began to build and was not able to
finish.' "

-- Luke 14:28-30

Jeffery Deaver knows a thing or two about writing. With more than 40
mystery and crime books to his name and 50 million copies sold, Deaver
stands as a titan of fiction authorship. His approach to writing is one
of meticulous preparation.

"I spend eight months outlining and researching a novel before I begin
to write a single word of the prose," he claims.

This quote underscores a fundamental truth about writing: the clearer
your roadmap, the smoother the journey from conception to completion.
Outlining is indispensable. It compels the writer to crystallize the
central point. It ensures a clear destination, compelling reasons to
reach it, and the necessary "equipment" for the voyage. For Deaver,
outlining is akin to measuring twice so as to cut once, a strategy that
eliminates aimless wandering through complex plots. For nonfiction
writers, an outline acts as a bridge between the chaos of a brainstorm
and the clarity of a final, well-structured composition. It is a
blueprint -- a logical plan -- which makes the writing phase almost
effortless when combined with the drafting power of AI.

In the realm of prompt engineering, using an outline to guide AI in
stepwise fashion is called "skeleton of thought." Based on the
"chain-of-thought" prompting method, the underlying principle is that AI
performs better at smaller, sequential tasks, represented by the
sections of a detailed outline or "skeleton." For example, commanding AI
to, "Write an article based on this transcript" yields unpredictable
results (at best). If, instead, you hold its hand through an outlining
process before generating the article one section at a time, you retain
control over both the intermediate steps and the final output. A
high-level outline functions as a special kind of prompt -- a roadmap to
navigate toward a more refined and cohesive piece of writing.

Because outlining is so crucial to great writing, I've broken this step
into two pieces, with a chapter on each phase:

-   **Phase 1** (this chapter) corresponds to the "**Organization"**
    stage of the creative process, in which you deconstruct your source
    material into its component ideas and zero in on the main point.

-   **Phase 2** (next chapter) corresponds to the "**Distillation"**
    phase and takes the main point as the cornerstone for building a new
    outline out of the "building blocks" you assembled in Phase 1.

While this may seem like a lot of work just to create an outline, the
value becomes evident when you reach the "**Expression"** stage, with
little left to do but command the AI to draft the article one section at
a time.

## **Deconstructing Your Source Material**

Deconstruction begins by extracting the essence of the raw, meandering
paths of your transcript. **Remember:** A one-hour-long podcast produces
a 5,000 to 10,000-word transcript. That's a lot for a human to hold in
their head at once. But with AI models, we can make it legible.

### **Step 1: Map the Terrain (Timestamped Outline)**

The first step of deconstruction is creating a territory map by breaking
down the transcript into its constituent parts. Start by putting your
transcript in a working document (Notion or another word processor)
under a large header, "**Transcript**."

Next, paste or attach the transcript into Claude's chat box, along with
the following prompt:

![](./book_media/media/image58.svg){width="4.5in"
height="3.1173611111111112in"}

This chronological summary of the conversation should provide you with a
bird's-eye view of the flow of ideas, topics, and their interconnections
throughout the recording. The timestamps and headers segment your
content into manageable sections -- like a table of contents -- which
will also help you locate specific sections of the transcript in full
detail later

Here's what my outline looked like, based on the 10-minute voice memo I
recorded on a quick walk:

![A list of information on a paper Description automatically generated
with medium confidence](./book_media/media/image59.png){width="4.5in"
height="1.9809437882764653in"}

![A list of information on a paper Description automatically generated
with medium
confidence](./book_media/media/image59.png){width="4.499975940507436in"
height="4.5723436132983375in"}

### **Step 2: Cheat Sheet Outline**

After completing your timestamped outline, the next step is to prompt
Claude to produce a "cheat sheet outline." Unlike the timestamped
outline, which provides a chronological framework of the conversation,
the cheat sheet goes deeper -- looking at the key themes, stylistic
nuances, and most memorable phrases from the conversation. It outlines
ideas not by when they were expressed but by their theme, substance, and
relevance.

Continue your dialogue with the following prompt:

![](./book_media/media/image61.svg){width="4.5in"
height="3.0409722222222224in"}

Claude produced the following cheat sheet inventory, which I then copied
and pasted into Notion:

![A paper with text on it Description automatically
generated](./book_media/media/image62.png){width="4.4998184601924756in"
height="3.0803674540682415in"}

![A paper with text on it Description automatically
generated](./book_media/media/image62.png){width="4.696842738407699in"
height="3.3327941819772526in"}

### Organizing **Additional Building Blocks**

The cheat sheet is a kind of skeleton of your content, but as it stands,
it still contains mostly *summary.* We want to support this summary with
the most important specific points, excerpted in full detail. Sometimes
a single line of your transcript or brain dump may speak to the main
point in a way that gets lost in the broad summary.

In this next step, we're picking through the material, looking for gems
-- excerpts and assets -- that might suggest a particular direction for
the overall outline once we get to the distillation/reconstruction
phase. The additional building blocks and actions to obtain them
include:

-   **Source List**: Compile all references made throughout the
    conversation for further research and credibility.

-   **Anecdote Bank**: Collect compelling stories and analogies that can
    be used to illustrate points vividly.

-   **Visuals**: Note any descriptive language or rhetorical devices
    that can bring your content to life for readers.

-   **Timeline**: Construct a timeline of key events or milestones
    covered to maintain chronology where necessary.

In our fractal expansion, these building blocks correspond to the social
media assets we generated for our podcast show notes -- providing the
raw materials for the next phase of reconstruction, where they will be
organized and polished into a coherent narrative.

You can refer back to Chapter 6 for the prompts I use to extract quotes
and links. You can play around with variations on the following prompts
for the other assets but don't get boxed in. Think for yourself about
how best to write the prompts to extract the unique building blocks your
content contains.

To obtain these assets, continue the conversation with Claude (you need
not reupload the transcript):

**For Visuals**

![](./book_media/media/image64.svg){width="4.5in"
height="1.1729166666666666in"}

**For Anecdote Bank**

![](./book_media/media/image66.svg){width="4.5in" height="1.125in"}

**For Timeline**

### ![](./book_media/media/image68.svg){width="4.5in" height="1.0104166666666667in"}**Step 3: Nailing the Point**

Armed with your cheat sheet -- enriched with condensed knowledge --
you're ready to home in on "the point." This is the culmination of the
divergent phase and the pivotal moment where you determine the key
message that will guide the reconstruction of your ideas into a coherent
narrative.

Continue the conversation:

![](./book_media/media/image70.svg){width="4.5in" height="1.325in"}

Note that this step mirrors the prompt we used in the podcast notes
chapter to find the "main idea." As with that process, you can provide
any additional context or hunches that you have about the main idea to
enhance the output and then iterate based on the suggestions. You can
combine the best elements or rework the wording until you have something
strong and *to the point.*

After some iteration with the AI, I crystallized the main point of my
voice recording as follows:

> "AI transcription enables writers to capture their best ideas while
> walking and talking, as nature and physical movement provide a vital
> boost to the creative process."

Once identified, this statement will serve as the Archimedean point
between the deconstruction and reconstruction phases and the measuring
stick by which you'll decide what makes it into your article and what
gets left out. Paste this thesis statement at the top of your page in
Notion, above the transcript, timestamped outline, and cheat sheet.

In the next phase, you will identify which ideas from the transcript's
source material align with and bolster the thesis. These, you will keep
while discarding the tangents. In this way, you will distill your
10,000-word transcript into a 500-2,000-word blog post or article that
people will not only read, but that will move them to action.

[Chapter 10]{.underline}

[]{#_Toc152566406 .anchor}DISTILL

Reconstructing Your Outline

*"We can rebuild him.* *We have the technology.* *We can make him\
better* *than he was.* *Better ... stronger* *... faster."*

--Â Opening narration from The Six Million Dollar Man

With the main point established, you can now begin the reconstruction
phase. Your article's thesis now commands the top of the page -- guiding
the structure that will emerge from the tangle of thoughts below.

Below this sits your rich source material, segmented into an organized
Cheat Sheet, and the full transcript below that. Now, you will begin the
process of crafting a new outline, with the main point to guide you.
This phase is about distilling the key ideas from your source material
and aligning these elements within a logical framework. With AI's
assistance, we will carve out a structured outline from the raw material
-- like a sculptor chips away at a block of marble to form the rough
contours of his vision before getting out the smaller chisel. The
reconstructed outline will then serve as a detailed roadmap for your
writing journey.

In Notion, each section header can be collapsed into "toggle headers,"
allowing you to expand and contract your view so that you're not
overwhelmed by all of the content at your disposal.

![A screenshot of a paper Description automatically
generated](./book_media/media/image71.png){width="4.5in"
height="3.759027777777778in"}

## **Shaping the Outline: From Broad Strokes to Fine Detail**

Our first restructuring prompt creates a broad outline based on the main
point. Again, you can continue the conversation with Claude, so that it
retains the context of the full transcript and your intermediate
summaries as it reasons through the new structure of the article:

![](./book_media/media/image73.svg){width="4.5in" height="1.14375in"}

Here, you are drawing on the LLM's strengths as a reasoning engine
capable of processing large volumes of text. Claude's first pass lays
the groundwork, saving your mental bandwidth for refining and feedback.
After reviewing its initial outline, you can either continue prompting
with suggestions, like this:

![](./book_media/media/image75.svg){width="4.5in"
height="1.0583333333333333in"}

Or you can do a manual edit. Just copy the draft outline into your
working document, edit it to your liking, and then feed it back to
Claude, saying:

![](./book_media/media/image77.svg){width="4.5in"
height="1.0298611111111111in"}

A sense check at the end is always wise, as it gives Claude a window to
provide feedback on connections you might have missed or areas for
improvement. I am routinely amazed by Claude's capacity for high-level
reasoning (as well as at ChatGPT's) about a wide range of topics. Its
ability to construct "auras of meaning" makes Claude a perfect writing
assistant and can help you through the gnarliest of writer's blocks if
you take the time to fill Claude in on your thought process. This is
especially true in the outlining phase, where you are dealing with broad
associations among ideas, but this mutual sympathy between human and AI
extends to every stage of the creative process, including writing.

## **Frameworks: Structuring Your Narrative**

In structuring your content, the idea of a "logical" order is open to
interpretation. The ordering that makes the most sense can take diverse
forms, depending on the *framework* you decide to use. The most basic
framework for a written composition is what you were taught in grade
school: a beginning, a middle, and an end, or introduction, body, and
conclusion. However, within the body, the ideal ordering must also be
considered. As a mental shortcut, ask yourself if the content you are
working with might lend itself to one of the following common frameworks
before determining the final order:

-   **Before and After**: Illustrating the contrast between pre- and
    post-solution scenarios.

-   **How-To Guide**: Offering a step-by-step approach to achieving a
    goal.

-   **Case Study**: Detailing a real-world application and its outcomes.

-   **Listicle**: Presenting information in a bullet-point format for
    clarity.

-   **Myth-Busting**: Correcting common misconceptions and offering
    alternative answers (often written in list form).

-   **Comparison**: Weighing different approaches side by side.

-   **FAQ**: Addressing common inquiries directly.

Most industries have their own bespoke frameworks, as well:

-   **Marketing:** "Problem-Agitate-Solution" (PAS) or
    "Attention-Interest-Desire-Action" (AIDA)

-   **Engineering/Technical**: Standard-Operating-Procedures (SOPs)

-   **Education**: Lesson plans

-   **Law:** legal briefs

These specialized frameworks are tailored to convey information
effectively within their respective fields. The choice of framework
hinges on your material and your audience.

Often, the content will suggest a fitting framework. For example, I once
wrote an article based on a podcast interview with the CEO of Burning
Man. The topic was the "10 Principles" that guide the festival. In that
case, using the "Listicle" format was obvious. The order of the ideas
was the chronological order of the principles as they have been codified
by the Burning Man organization. Here, my job was straightforward: clean
up the transcript and rewrite the guest's portions in the third person,
as quotes.

In another instance, I started with a podcast interview between a
well-known biohacker/fitness guru and his guest -- another prominent
biohacker. The two health experts had much in common about their
approaches, but also some key differences worth highlighting. This
content dictated in favor of a "comparison" format, which contrasted
their perspectives on six different areas of well-being in the following
order:

-   Diet

-   Sleep

-   Workouts

-   Supplements

-   Technology

-   Purpose/Meaning

Each of these areas got its own header and included a distillation of
quotes and key points about that topic from the interview. The order
here is subjective, and could have been arranged differently, but I
thought it made sense to start with the fundamentals (i.e., diet and
sleep), before getting into deeper and more advanced topics like
supplements and technology.

You can decide on a framework before or after you arrange the ideas in a
logical order. In some cases, the framework might be a prerequisite for
deciding the logical order. In my demonstration article, I first tried
to arrange the points in a logical order without a framework and found
the resulting outline to be disjointed. However, when I instructed it to
follow the **"Problem-Agitate-Solution"** framework, I got a much more
compelling progression:

![A white text on a black background Description automatically
generated](./book_media/media/image78.png){width="4.5in"
height="3.963888888888889in"}

After reviewing the output, I found that I only needed to move a few
points to be satisfied with the overall flow of ideas.

## **Refining the Blueprint: Detailing the Outline**

After you have your working skeleton outline, the next step of the
"**Distill"** phase is to flesh out the bare bones with the key details
from your transcript and Cheat Sheet.

For every section header of your outline, start by identifying
additional supporting points and examples from the transcript and cheat
sheet. You can manually drag and drop bullet points into your outline
(another handy feature of Notion's block-based editor). Or, if you want
to be ~~lazy~~ strategic, you can use a series of prompts to guide the
AI in helping you extract these details for each section:

![](./book_media/media/image80.svg){width="4.5in"
height="1.4777777777777779in"}

If you opt for the AI shortcut, you can replace the broad outline for
each section of the outline with the more detailed version, scrutinizing
it to ensure the proposed ordering aligns with your vision.

I recommend a hybrid approach, using AI as a first pass, but
supplementing with a manual selection process to make sure none of the
key points are getting lost.

At this stage, you can leverage the model's broad knowledge to expand on
areas where your initial content may be lacking substance. In writing
this chapter, for example, I leaned on AI to generate the full list of
"frameworks" based on the examples of the "Listicle" and "How-to"
formats. It suggested the "Before and After," the "FAQ," etc. While the
majority of your content should originate from your own expertise, you
can use AI to augment your knowledge in specific areas.

The more detailed your outline before you start generating the prose,
the better the results will be. But you don't need every last detail in
your outline before proceeding from outlining to the writing phase.

Remember, the outline is a living document. It will continue to evolve
through each iteration. At this stage, the skeleton is fully
articulated, but it isn't something you'd present to your readers until
you've had a chance to clothe it in lively and inviting prose. As we
move from the architectural phase of outlining to the expressive
drafting phase, we will acquire one of the most sought-after and
valuable skills of AI-assisted writing: matching the style of prose most
appropriate for our purpose and audience.

[Chapter 11]{.underline}

[]{#_Toc152566407 .anchor}EXPRESS, PT. 1

Voice Matching

"A well-dressed sentence walks down the page with a certain attitude."

-- William Zinsser, author of *On Writing Well*

"What's the best AI-powered platform to convert an audio file into a
well-written article, using my general style and voice?"

The question was posed in the form of a tweet by a well-known internet
influencer who leads a small fitness empire under his own
multi-million-dollar personal brand.

"**\@chdeist** does this" replied a friend who was familiar with my
system.

Minutes later, I was messaging back and forth with the e-celebrity,
trying to balance my confidence in the system I'd developed with a
desire not to blow the opportunity at hand. After some back and forth, I
offered a short demo, showcasing the tools I use. Intrigued, he
connected me with his team on Slack to discuss further.

It turned out the team thought they had already tried everything to
mimic their boss's distinct voice, butÂ none of the AI tools delivered
what they promised. It always took hours of manual editing and
back-and-forth to get the tone just right, to say nothing of the time
structuring the actual content of the article. So my first assignment
was framed as something of a longshot -- an "experiment," they called
it.

The assumption, or null hypothesis, in this experiment was that my
method would be no different. This was my chance to show them what I
could do.

## Ghostwriting + AI Voice Matching: A Match Made in Heaven

Before we get into the exact method I used to imitate my client's voice,
let's look at how Large Language Models perform at the simpler task like
imitating the style of a famous writer or public figure whose words are
part of their training data.

When I prompt ChatGPT to "rewrite the previous paragraph like
Shakespeare," I get the following:

> Before we mimic voices new,
>
> Let us see how Models do,
>
> Imitating styles of writers of yore,
>
> Whose words in training data they explore.

Bravo!

It can also match styles ranging from confident to friendly to
professional to casual. Just describe the tone you want in plain
language. Notion gives the above four options as presets, but let's try
something more unique, like passive-aggressive:

> "Oh, sure, these language models can apparently just *magically*
> create or change content into any tone you desire. They just
> inherently *know* how to write in styles like confident, friendly,
> professional, or enthusiastic. Must be nice."

This ability to absorb the patterns and nuances of different styles of
writing makes AI an ideal tool for ghostwriters like me seeking to mimic
a client's personal style. There are dozens of AI tools boasting
specialized voice-matching features, but you can get the best results
without paying another dime in monthly subscriptions using regular old
Claude.

# **Creating an AI Style Sheet**

For well-known writing styles, like Shakespeare, simple instructions
like "write in the style of William Shakespeare" are sufficient. Adding
examples of Shakespeare's writing would contribute nothing to the AI's
comprehensive training on Shakespeare's entire collected works, which
are in the public domain.

When dealing with individuals whose work is not contained in the AI's
training data, the scenario changes. In these cases, providing specific
writing samples is the best way to convey your desired style. No matter
how detailed or well-crafted your description may be, it will not
capture the full nuances of a style in the same way that an example can
convey. Put yourself in the AI's shoes and imagine that you are trying
to imitate Mr. Bean without ever having seen an episode based on
someone's verbal description. You would be hard-pressed to impersonate
the facial expressions and mannerisms without *seeing* his antics.

Thankfully, for the "experiment," the client's team gave me both
examples *and* instructions -- a set of guidelines describing the
desired voice, as well as a few sample articles exemplifying the target
style. I used this combination of instructions and examples to create
one consolidated reference document that I call a **"style sheet."**

Here is how you do it:

### **Step 1 -- Gather Examples**

Collect a few full-length articles or content samples that exemplify the
style you want the AI to emulate (whether your own or someone else's).
These will form the core of your style sheet. Look for samples that
align with the voice, tone, diction, sentence structure, and general
style you wish to replicate. There is no "ideal" length for your
examples. Claude can handle up to 500 pages, but 2-5 pages is enough.
Beyond that, and you will slow down Claude's responses with little
additional benefit.

### **Step 2 -- Analyze the Samples**

Read through the samples closely, taking note of distinguishing features
like:

-   Word choice and vocabulary

-   Sentence length and complexity

-   Tone (serious or conversational? Sense of humor?)

-   How do you address your reader? In the second person, as you? Or
    first-person plural, "We"?

-   How often do you begin a new paragraph?

Make a list of the attributes or write a paragraph about what makes this
style unique.

You can also outsource this step to Claude, and apply the following
prompt to one of your samples:

![](./book_media/media/image82.svg){width="4.5in"
height="1.3159722222222223in"}

Then, fine-tune the output, or merge that list with your own list of
observations.

### **Step 3 -- Compile these into a Brief**

Combine your examples and instructions into a PDF titled \[Name's\]
Style sheet.PDF. Use headers and formatting like bold text and quotation
marks to clearly delineate examples from instructions. The document I
used for this assignment was formatted as follows:

![](./book_media/media/image84.svg){width="4.063162729658792in"
height="5.070174978127734in"}

Whenever you want to write in the style of the brief, just attach this
PDF at the beginning of your drafting conversation with Claude.

Save the file in a convenient location where you can access it with just
a couple of clicks. That might be your desktop, a documents folder on
your computer, or a Notion page where you can easily copy and paste it.
Remember that anything you copy-paste into Claude that runs more than a
few hundred words will be converted into an attachment.

When it came time to submit my draft of the article for my client, I
didn't know how it would be received. Would my attempt to imitate the
client's voice be greeted with ridicule? Anger for butchering the
nuances?

After a day or so, the feedback arrived: "This is Fantastic!!! I
honestly wouldn't change a thing except the title."

Without AI, I could have provided a solid outline for the article -- a
roadmap for turning the long, meandering transcript into punchy
2,000-word polished prose. But I would have struggled to mimic the
nuances of the client's voice. With AI, I could get a close style match
for most of the text and then apply my "human touch" to identify when
the voice was off -- and fix it.

AI gives anyone the ability to transform any type of content into any
voice. This power to mimic unique voices is a double-edged sword.
Sophisticated phishing scams are on the rise, where scammers imitate
your friends and family members in AI-generated writing (or even
AI-generated speech!). But if you wield this skill with care and wield
it for good, and you need not hesitate to wield it. There's no law
against writing *all* of your articles in the style of your favorite
writer. I considered writing this entire whole book in the style of
William Shakespeare but decided to spare my readers the Iambic
Pentameter. Just give me one more allowance here as we transition to the
next chapter:

In the next scene, our plan's grand show unfolds,

With outline's bones and style's skin it holds.

Each sentence, in client's voice, we'll craft and make,

Our labor's fruit, alive, for our own sake.

Behold! this work, from careful thoughts it wakes,

And breathes first life, as new dawn breaks.

[Chapter 12]{.underline}

[]{#_Toc152566408 .anchor}EXPRESS PT. 2

Flesh on the Bones

"Then he said to me, 'Prophesy to these bones and say to them\... 'I
will make breath enter you, and you will come to life. I will attach
tendons to you and make flesh come upon you and cover you with skin; I
will put breath in you, and you will come to life. Then you will know
that I am the Lord.'"[[\
]{.underline}](https://www.biblegateway.com/passage/?search=Ezekiel%2037&version=NIV)

-- Ezekiel, 37:4-6

In the Bible, the prophet Ezekiel reports a vision in which stands
amidst a valley of dry bones. There, God commands him to tell the bones
what he is about to do. Just as breath entered dead bones in Ezekiel's
prophecy, you now stand ready to transform your bare-bones outline into
living words. The skeleton awaits only the sinew, flesh, and skin - the
style and voice that will allow your ideas to walk down the page with
attitude.

Your thoughts have been captured, organized, and distilled. The language
model has been primed to channel your unique perspective, based on your
source material, in your preferred style of writing. From here, you
could start writing solo and draft a great article yourself, but why not
continue the iterative process and see what our AI assistants can do?

Although your outline and organized source material provide a detailed
blueprint, don't treat them as the last word. In this phase, approach
your outline with fresh eyes. Remain open to surprises in the final form
your argument takes. Claude's first draft may surprise you.

Begin this phase by initiating a new conversation with Claude. The
accumulated length of your outlining conversation adds up to a lot of
context for Claude to process each time you submit a prompt and will
slow down the responses. In resetting the conversation, you will need to
provide the key context just once, at the beginning. This necessary
context includes an overview of the task at hand and a key to the
supporting materials you are providing:

1.  The "Style Sheet" created from the steps in the previous chapter.

2.  A single "source material" document containing the following, in
    order:

    -   Main point

    -   Detailed skeleton outline

    -   Menu of quotes/Cheat sheet outline.

    -   Timestamped outline

    -   Transcript

Returning to my demonstration article about writing-while-walking, I
decided to provide Claude with the role of a writer for *Outside
Magazine* as short-hand for a competent writer, with domain area
expertise on the topic of the article -- my experiment in
writing-while-walking.![](./book_media/media/image86.svg){width="4.5in"
height="3.1173611111111112in"}

"My mind is racing with ideas," Claude replied, "and I'm ready to begin
writing whenever you give the green light!"

## The Importance of Bite-Sized Drafting

From here, if I said "Proceed," Claude would churn out an entire article
conforming loosely to my outline. But instead, I chose to narrow his
focus to a single, short section of my outline:

![](./book_media/media/image88.svg){width="4.5in"
height="2.8409722222222222in"}

As with our earlier practice of polishing shorter transcript passages in
bite-sized chunks, we now draft article sections one at a time to keep
Claude focused. Going section-by-section prevents AI meandering and
enables course correction. I've found Claude more reliably addresses all
outline details when given a narrow scope.

When drafting articles section-by-section, AI models often conclude each
part as a standalone piece. This results in repetitive or vague summary
sentences that disrupt the flow between sections. One way to fix this is
to simply delete repetitious final sentences so one section flows
directly into the next. Alternatively, you can provide Claude some
overlapping sections of your outline, i.e., include the end of Section
1, header for Section 2, and first bullet point of Section 2. With this
context, Claude will write a smooth transition suited for continuity.

The optimal length for sections in your article depends on the total
number of sections and the target article length. For example, if your
2,000-word draft has 5 sections, consider \~400 words per section. I
assigned 100 words to this opener section of my article given my
500-word article target. Treat these as starting points -- adjust to
suit your needs. Pad each request slightly over your per-section tally
to give yourself a buffer for editing out sections like the unwarranted
conclusion sentences at the end of each section.

## Enriching AI First Drafts

While a detailed outline provides critical direction for Claude,
additional customization helps refine the draft. As you draft, you may
realize that certain sections require more elaboration or specific
examples that weren't captured in the initial outline.

Rather than leaving those details to chance, you have a few options for
expanding your prompts. One option is to modify your bullet point
outline saved in Notion (keep it handy). Insert additional instructions
directly in your bullet point outline, formatted to stand out -- Claude
will follow guideposts from within the document, like **\<embellish X
point\>,** when the updated bullet point outline is attached to the
prompt window. Alternatively, you can offer this guidance apart from the
outline, with the outline in quotation marks and the instruction outside
the quotations. For instance, ask Claude to focus on improving
connections between ideas, or transitioning smoothly from the previous
section.

When transforming interview transcripts into article drafts, you'll want
to be strategic in your incorporation of the guest's remarks as quotes.
Introduce guests naturally early on with full name attribution. Then
vary between repeating their name and using pronouns for clarity. Seek a
balance between exact quotes and paraphrasing. Preserve succinct,
eloquent soundbites where the speaker's personality shines. You can
lightly edit these quotes as needed for brevity, clarity, and relevance,
but for more sweeping changes, make it a paraphrase. For proper
formatting of quotes, I've found success by instructing Claude upfront
to adopt *New Yorker* profiling conventions - their non-fiction norms
for quoting and attribution. I can then include full quotes -- or even
paragraph-long excerpts from the interview -- in the outline and get a
good balance of quotation and paraphrasing in the output.

Another powerful AI capability is embedding supportive content from
outside documents into your draft. For instance, you may know a lengthy
research paper holds relevant data points for a section of your outline,
but finding the exact passages would be time-consuming. Instead, provide
Claude the full external source along with the relevant outline section.
Specify the point or points in your argument that require additional
credibility or evidence and ask Claude to identify the most persuasive
statistics or textual backing from the attached material. Make it clear
whether you want a pure summarization or a mix of paraphrasing with
verbatim quotes, along with attribution of the source. For example:

![](./book_media/media/image90.svg){width="4.5in"
height="1.7638888888888888in"}

## The Power and Pitfalls of "Continue Writing"

After drafting a given section with Claude, copy and paste the output
into your working document to polish. After editing a passage, provide
the revised version for Claude's review. Say, "Here is how I chose to
tighten up this section: \[quotation\]. Now, continue writing the next
section based on the following outline: \[Outline\]

This prompting allows Claude to digest your exact phrasing choices,
tone, and narrative style. In this way, Claude can sharpen its instincts
throughout the conversation to better echo your preferences. Over time,
these iterative dances build intuitive rhythm -- rapport even -- while
your skeletal outline comes to life.

You can even employ the **Continue writing** prompt without additional
instructions or outlines to deepen the details on a particular topic.
For instance... *if I have a point that I want to elaborate on but don't
quite know how to approach it, I might start with a simple sentence or
two, then prompt the AI with "continue writing from this point." This
allows the AI to build upon my initial thoughts, providing more depth
and nuance to the point.*

I generated the above text in italics by feeding the previous two
paragraphs, along with the **Continue writing** prompt. This capability
taps into the AI's predictive power as a souped-up "auto-complete." When
used judiciously, it is a valuable tool for fleshing out areas that
require further explanation or when an example is needed to clarify a
point.

Be warned, though: If you use this function too often, your writing will
start to resemble the dreaded AI-generated garble we are working so hard
to avoid: *So many words, signifying nothing*. **Continue writing**
works best when you can supplement the instruction with some additional
source material or pointer, such as "continue writing on the theme of
getting creative juices flowing." Without these instructions, you're
just drawing on the AI's training data and best guesses of what you are
trying to say. The writing ceases to be yours. You've let the AI dance
by itself.

My final advice on drafting reinforces the point I've been emphasizing
since the beginning of this book. The skill of prompting an AI writing
assistant is acquired by doing -- not talking or reading. My chats with
Claude never follow the same structure. Each piece of writing has its
own unique goals and needs. In the early stages, my conversations often
spanned over 50 pages just to produce a single 2,000-word essay.
However, I have refined my approach over time to make the "dance" much
shorter. Each new project will teach you the nuances of what flows and
what doesn't. What matters most is having the courage to commence that
first dance. With patience, dry outlines shall come to life.

[Chapter 13]{.underline}

[]{#_Toc152566409 .anchor}REFINING, EDITING & FINISHING TOUCHES

"The sculptor arrives at his end by taking away what is superfluous."

--Â Michelangelo

Michelangelo believed that within every solid block of marble he carved
was a masterpiece waiting to be revealed. His famous "Prisoners" --
half-finished sculptures that appear trapped in the stone -- convey a
sense of potential and the all-too-human struggle toward perfection.

At this stage, our working draft saved in Notion is like these
Prisoners. The essence is visible, yet it awaits a few final taps of the
chisel to bring its final shape into sharp relief.

This chapter focuses on those finishing touches that will refine your
writing and add clarity and definition to the rough edges. You'll learn
to use AI to craft captivating hooks and compelling calls to action
while smoothing transitions to carry the reader through your narrative.
You'll also learn how to employ Claude as an expert copy editor to
sharpen dull language and buff away the nonessential material until your
composition gleams. Finally, you'll learn three ways to leverage AI to
make your writing sound *more* human and less robotic.

## 

## **Bookends: Hooks and Calls to Action**

British advertising tycoon David Ogilvy used to say that a copywriting
team should dedicate at least half the time they spend on a campaign
brainstorming the opening hook alone. After all, it's the most-read part
of any copy and your best chance to get the reader's attention. An
effective hook combines an element of surprise with the promise of
value. I tend to wait until the end of the writing process to craft my
hook after I've already immersed myself in the topic and explored it
from various angles.

Here, you can use a variation on the RTF framework (role-task-format) to
get the creative juices flowing:

![](./book_media/media/image92.svg){width="4.5in"
height="3.1173611111111112in"}

You can also compile a list of examples in the form of a "swipe file,"
comprising the most effective hooks you come across.[^5] A swipe file
populated with opening hooks can be attached to a prompt like your style
sheet. But instead of matching a specific voice, it provides samples of
the narrative punch you're aiming for.

![](./book_media/media/image94.svg){width="4.069951881014873in"
height="3.5009120734908135in"}

Once you've created your swipe file, you an upload it as an attachment
along with your draft and inform Claude that you would like to generate
some potential hooks for the article in the spirit of the hooks
contained in the swipe file.

![](./book_media/media/image96.svg){width="4.5in" height="2.83125in"}

Then, pick your favorite or synthesize the best elements into a single,
powerful opening that grips your reader before they have a chance to
click away.

The right hook can make all the difference in whether a reader stays for
the whole show or leaves after the first act. If you've done your job,
the reader will reach the conclusion with a new perspective. You will
have earned their trust. Now, what will do you with that trust in the
final words? In modern, digital writing, the conclusion has one purpose:
propelling readers to clear action.

Suppose you offer a service that simplifies the solution to a problem
you explored in your article. The call to action presents the chance to
transform readers from passive consumers of information to active
participants in your offering. For a book chapter, the call to action
invites the reader to continue to the next chapter. For articles, it may
promote engaging further with related content you've created.

Your call to action (CTA) should align with your content strategy.
Consider these options:

-   Inviting readers to join a newsletter for ongoing dialogue

-   Suggesting the next article to read, to go deeper into the topic

-   Encouraging readers to share the content with others

-   Registering for an upcoming event on the topic

-   Scheduling a consultation for tailored advice

The aim here is to transform the reader's newly acquired knowledge and
enthusiasm into a specific, meaningful action. The hook grabbed their
attention; your CTA will harness that focus, turning it into the
momentum that benefits both the reader and your goals.

## Refining Edits: Smoothing Transitions & Eliminating Redundancies

With our hook and call to action in place, we can turn our
AI-assistant's eye to identifying awkward transitions, redundancies, and
gaps in the logical flow.

We can once again begin a new chat, provide the full draft, and then ask
Claude a simple question:

![](./book_media/media/image98.svg){width="4.5in"
height="3.4034722222222222in"}

Note that we are not asking Claude for a complete spelling and grammar
check. While LLMs are capable of doing such a review, you are better off
using a custom AI-powered tool like Grammarly -- or even Microsoft
Word's spell check feature -- to make these final edits.

If you assign too many tasks at once, it dilutes the focus of your
prompt. Even the above general editing prompt -- asking the AI to
identify verbosity, redundancies, long sentences, and improper use of
adverbs and adjectives -- will yield fewer suggestions for each
criterion than if you broke them out into separate prompts. Thus, a
broad prompt like this can help identify the most glaring errors, but a
series of more specific prompts will provide the AI with a more focused
context for each editing task.

For instance, if you're most concerned about awkward transitions or
redundant phrases, a focused prompt like this might be most effective:

![](./book_media/media/image100.svg){width="4.5in"
height="1.1729166666666666in"}

You might then follow up with prompts that address these specific areas.
For smoothing transitions:

<figure>
<img src="./book_media/media/image102.svg"
style="width:4.64033in;height:5.53904in" />
<figcaption><p>The first, darker box contains the human prompt while the
lighter box contains Claudeâ€™s actual reply to this
question.</p></figcaption>
</figure>

Or for combining redundant sentences:

![](./book_media/media/image104.svg){width="4.5in"
height="3.0409722222222224in"}

This approach surfaces more granular errors and allows for targeted
corrections. Like a sculptor inspecting rough edges, our goal is to
polish these remaining imperfections through deliberation and care.

## Humanizing Touches

In the course of writing this book, I've often asked myself whether it's
possible to use AI to make your writing sound ***more human.*** I
believe that it is.

To conclude this part of the book, I offer the following three prompts
to make your writing sound less robotic.

### Vary Sentence Length

The first method is to alternate short and long sentences. This
suggestion comes courtesy of Joshua Lisec's ***Best Way to Say It***
methodology. One drawback of drafting with AI is that its sentences tend
to have uniform length and, thus, a dull, mechanical cadence. The best
writing has a rhythmic quality, alternating between longer, more
descriptive sentences and shorter, punchier phrases for emphasis.

Here's a prompt you can use to identify the sections most in need of
variety:

![](./book_media/media/image106.svg){width="4.5in"
height="1.3159722222222223in"}

Note that you can also include this guidance in your style brief so that
varied sentence length is "baked in" to the drafting process.

### Visual Examples

The second humanizing prompt identifies vague areas that could be
boosted by a personal anecdote, analogy, or visual example:

![](./book_media/media/image108.svg){width="4.5in"
height="1.382638888888889in"}

This advice likewise comes from Lisec's course, as a way to "hypnotize"
your reader and make your content a more immersive experience.

### Mimicking the Greats

Lastly, you can prompt AI to rewrite dry passages in the style of your
favorite authors:

![](./book_media/media/image110.svg){width="4.5in" height="0.94375in"}

Certain authors will be more useful than others for your brand of
writing. Are you a marketing professional? Try David Ogilvy, or for a
more modern reference point, Alex Hormozi. Do you work in medicine?
Consider consulting the voice of Dr. Atul Gawande. Literary nonfiction?
Maybe you're looking for elements of Michael Pollan's or Malcolm
Gladwell's trademark style.

I have come to appreciate the usefulness of adding a touch of Dave
Barry-style humor to my dull manuscripts.

Just remember to use these as suggestions. Don't replace the original
text with the AI's exact output but use it as inspiration and borrow
bits and pieces, while leaving your original phrasing mostly intact.

When I try the Tom Wolfe version of this on the paragraph above, for
example, I get the following output:

> See here, splendid scribes! In pumping up your prose with
> cyber-assists, retain your authority! Let artificial intelligence be
> your muse, not your overwrite! Take its offerings like a
> bouillabaisse - pluck tasteful morsels of metaphor to integrate
> seamlessly into your original masterpiece. Use a delicate hand,
> darlings! Never forget you remain the auteur, the artiste in charge of
> this lyrical canvas!

This paragraph would be out of place if I reproduced it in its entirety.
But I might borrow a few choice phrases to spice up my writing (like a
bouillabaisse).

## Turning the Page: From Articles to Books

This part of the book has walked through the essential steps to becoming
a CODER of meaning -- a "natural language programmer" -- with a
practical understanding of the elements of prompt engineering for
long-form content.

In reworking a transcript into an article, we followed these steps:

-   **Captured** our ideas within a single transcript, serving as the
    raw "source material" for crafting a concise, polished article.

-   **Organized** the source material, by breaking it down into smaller
    components and mapping it out with timestamped summaries and
    inventories of quotes and key ideas.

-   **Distilled** the central "point" from the big picture within a
    logical, reassembled outline.

-   **Expressed** these distilled ideas in prose in the style of our
    choosing.

-   **Refined the text**, filling in gaps, crafting hooks, and creating
    smooth transitions.

You now have everything you need to implement this system with your own
source material and start "repurposing upwards." Once you have developed
the "mechanical sympathy" necessary to turn a single pillar piece into
an article, you will start to imagine new possibilities for writing
longer and more elaborate content. Regardless of the length and format
of the final output, the creative process of transforming a complex and
chaotic web of ideas into a clear and compelling narrative follows this
same four-stage progression -- from the divergent steps of
"**capturing"** and "**organizing**," to the convergent steps of
"**distilling"** and "**expressing."**

Now, it's time to take this systemized approach to creativity to its
logical conclusion -- climbing to the apex of the content pyramid, where
you can crown yourself as the ultimate authority in your domain. Prepare
to author the future. Get ready to write your book.

PART 4

CODE Your Minimum Viable Masterpiece

[Chapter 14]{.underline}

[]{#_Toc152566410 .anchor}CAPTURE AND ORGANIZE

Outlining a Book IN Your Second Brain

*"The impediment to action advances action.\
What stands in the way becomes the way."*

-- Marcus Aurelius

"Be regular and orderly in your life, so that you may beÂ violentÂ and
original in your work."

-- GustaveÂ Flaubert

The average author takes three years to write a book. In that time, Ryan
Holiday didn't just write one; he wrote three. The last of these, *The
Obstacle Is the Way*, not only claimed its place on the bestseller list
but also captivated over 100,000 modern readers with the timeless
philosophy of Stoicism, which embraces life's struggles and pleasures in
equal measure.

How did he do it? It turns out that Holiday had a secret weapon:
notecards. Holiday carried 3 x 5 index cards everywhere, scribbling down
ideas, quotes, and stories as he read and went about his daily life.
This system was borrowed from his mentor, Robert Greene, the author
behind mega-bestsellers like *The 48 Laws of Power*. Greene, too, used
notecards to capture source material from the vast array of books he
consumed. As he read, he highlighted important sections and jotted down
notes in the margins. Later, he transferred these annotations onto
notecards, allowing him to deconstruct the information and identify
patterns that would eventually form the foundation of his books.

After amassing enough material for a full book, Holiday followed suit.
He would sit down and rearrange the content at will -- pulling from the
treasure trove of material he had captured on notecards over time. This
idea capture and organization method made the second writing phase easy.
With notecards in order, he could just fill in the gaps and call it a
day.

Note that Holiday didn't produce his books through laborious stints of
unbroken "deep work" from an isolated cabin in the woods. Instead, he
developed a *system* that allowed him to finish most of the work on his
book before he ever started writing. In doing so, he was keeping in line
with a rule of thumb that sounded illogical when I first read it in
Tiago Forte's book, *Building a Second Brain*:

> "Only start projects that are already 80 percent done."[^6]

For our purposes, we can update the advice to "Only start writing a book
that is already 80 percent written."

How can you write 80 percent of a book before starting it? To resolve
this seeming paradox, let me clarify: You don't need 80 percent of the
content to be polished and arranged in its final form. You just need to
have gathered most of the raw ideas and insights before committing to
crafting your book's outline. Like Holiday, you do so by *capturing
ideas over time* so that the groundwork is laid well before the
"official" beginning of the project.

## Capturing Your Source Material

In the last few years, I've written books for a libertarian attorney, a
progressive psychologist, a Republican activist, as well as a
naturopathic nutritionist, an extreme biohacker, and a B2B marketing
professional. My ghostwriting clients are a diverse bunch, but they all
share one thing in common: They all came to me with a large enough body
of existing pillar content to fill the pages of at least one book.

For one client, I turned 100+ hours of teleconference proceedings into a
comprehensive 200-page "12-step guide" for citizen activists dedicated
to removing fluoride from their municipal water supply.

For other clients with podcasts or radio shows, I've repurposed 10-30 of
their interviews as source material for focused, timely, topical books.
In some cases, I've acted as both a podcast producer and ghostwriter.
Here, I orchestrated the interviews with select guests to *source the
source material* that we needed to craft the book. This strategy has
allowed me to be the first to publish on trending topics before they
reach the mainstream and sign contracts with publishers even before the
content is recorded.

### Identifying Your Existing Intermediate Packets

As with articles, writing a quality book with AI hinges on having source
material. Audio transcripts are my favorite form to work with, but any
of the following are fair game:

-   **Pillar pieces:** Podcasts, YouTube videos, and presentations

-   **Micro-content:** Twitter, Instagram, or LinkedIn posts

-   **Newsletters/blogs** (both published and unpublished drafts)

-   **Voice memos/miscellaneous**: notes on your phone.

In Forte's framing, these all represent "intermediate packets" --
smaller blocks of content that can be snapped together into larger
structures like LEGO bricks. Thinking in terms of intermediate packets
and existing source material reframes the process of writing a book from
one that requires long uninterrupted blocks of forced effort to one
where you can make consistent progress in short bursts. Wherever you are
starting, take stock. Write a list of everywhere your intermediate
packets live.

If you are working with text-based source material, like blog posts or
written tweets, compile the links or documents all in one place.

If you're working with audio or video, get an
[Otter.ai](http://Otter.ai) account and start transcribing the content
related to your book. Then, export these transcripts to a folder in your
chosen file storage system or note-taking app.
[Otter.ai](http://Otter.ai) also offers a handy phone app, that lets you
record and transcribe your ideas while you're on the go. You can capture
thoughts that pop into your head during a morning jog or while you're
stuck in traffic before they slip out of your head.

### Structuring Your Second Brain

Some people will prefer the simplicity of an analog system like Ryan
Holiday's box of notecards -- organized by broad topic. Tiago Forte
recommends creating a simple file directory on your hard drive,
containing your intermediate packets sorted into folders for different
projects, areas, resources, and archives.

My preferred "second brain" system utilizes the versatility and
convenience of a cloud-based workspace, built within (you guessed it)
Notion. Notion allows me to create dashboards for each writing project,
with customized content databases, dynamic outlines, and a host of AI
features and integrations that save me time and effort when sifting
through large volumes of information. The "Save to Notion" browser
extension, for example, lets me extract the full contents of any page on
the internet into a specific content database with just a few clicks. I
can configure that database to then generate summaries automatically or
extract key quotes with AI.

Note-taking apps like Evernote offer similar integrations with your
browser, but nothing I've seen compares to the power and flexibility of
Notion's all-in-one workspace approach -- combining databases, word
processing, and now AI into a sleek, aesthetic experience.

Whatever tool you choose, remember that building a second brain system
is a personal endeavor. Forte's book can give you some helpful
principles, but I've found that pre-made templates never align with my
idiosyncratic thinking patterns. Over time, I've developed my own
structures within Notion that feel intuitive to me, and I'm happy to
advise others. But it's best to let your second brain emerge organically
from sustained use, customizing a system to support your unique creative
flow.

### **Capturing Others' Ideas**

Your primary source material should come from your *own* intermediate
packets -- things you've written or spoken. But every author leans on
external sources of inspiration and knowledge in a variety of formats,
from book highlights to articles, research papers, and blog posts.

"No one creates anything out of a pure void," notes Forte, "We all stand
on the shoulders of our predecessors."

As a content creator, you can and should borrow ideas from others with
two caveats:

1.  You should always put your own spin on it

2.  You must provide generous attribution.

"Giving credit where credit is due doesn't lessen the value of your
contribution -- it increases it," adds Forte*.*

By quoting Forte in this way, I am following my own advice --
attributing the idea to the original writer and directing my readers to
the source. These quotes from Forte's book, *Building a Second Brain*,
have been sitting dormant -- waiting to be used in this chapter -- since
I first highlighted them when I read the book. The purpose of a second
brain is to capture and store information, like quotes from books you
read, so you can access it when needed. This is a slow and steady
process -- not a sprint. The key is consistency over a long period of
time, and the key to *consistency* is having a system that's so easy you
don't have to think about it.

## **Organize: Structuring Your Table of Contents**

With your content captured and assembled in a central database, you can
get a better sense for the contours of your book. Now, your task is to
organize your material into a broad-brushed outline so you can begin to
whittle that down to the essential themes.

The biggest difference between outlining an article and outlining a book
arises from the volume of material involved in writing a book. For a
podcast episode, we could get our map of the terrain from a timestamped
outline. But a database containing 50 to 100 podcast episodes can add up
to over half a *million* words. Even Claude can't summarize that much
material in one pass.

As we zoom out, attempting to see the whole picture from this heap of
text, we can see the same fractal pattern continuing to unfold in our
organizational process. For books, unlike articles, there are two
distinct phases of outlining:

First comes the overarching outline for the entire book -- your table of
contents, i.e., the broad chapter headers that support your book's
central theme or main point. You need this high-level outline before you
can begin organizing and outlining the content *within* chapters.

Second, once you've defined your chapter topics, you need to create
detailed outlines within each chapter. Here, the main point of each
chapter shapes the flow of ideas, similar to how the main point guides
the structure of an article.

At both levels, we are still applying the same general progression that
we learned in the previous section of the book:

-   Deconstruct your source material into core ideas. **(organize)**

-   Identify the main idea. **('the point')**

-   Reconstruct those ideas into a logical order based around the
    central point. **(distill)**

-   Draft the text based on the new outline, either by yourself or with
    AI, one section at a time **(express)**

Before AI, my "deconstruction" method involved printing out all the
transcript materials and reading through them with a highlighter to
avoid frying my eyeballs from too much screen time. Through this
painstaking process, I would start to notice patterns taking shape.
Certain keywords would become connected in my mind, and I would start to
group them under umbrella topics or tags. Soon these topics and keywords
would form "buckets" -- clusters of related points and ideas that fit
together. From these buckets, a hierarchy of ideas would begin to emerge
from the chaos until I had a branched tree of sorts with the broad
topics branching into smaller and smaller topics.

Today, however, you can leverage an AI-powered second brain to save your
own brain cells (and your eyeballs) from much of that headache. No,
despite the hyped-up promises, AI cannot write your entire book for you,
but it can help at each stage -- beginning by imposing order on a large
volume of material and helping you to "zoom out" on the big picture.

### Case Study: **B2B Software Thought Leader**

One of my clients, a thought leader in the B2B Software space,
illustrates how we can use AI to assist the outlining of the book. Let's
call him Jason. Jason's content library was brimming with potential. It
contained hundreds of podcast episodes, dozens of LinkedIn posts, and a
handful of long-form "manifestos," each offering insights into the
future of the SaaS (software as a service) industry. Yet, in its raw
state, this wealth of material lacked the structure and organization
necessary for a cohesive narrative. My client had the ideas and the
content but not the time or energy to mold it into a coherent narrative.

He did, however, have a big-picture vision for the book's structure.
Jason envisioned each chapter applying his unique perspective to a
different department of a modern B2B SaaS company: sales, marketing,
product, customer success, operations, and so on. These became our
chapter headers. This vision was our starting point -- a rough map to
guide us through the content wilderness. It gave us enough structure to
begin identifying the most relevant content pieces (the "intermediate
packets") for each planned chapter.

To organize this wealth of source material, I set up a Notion dashboard
to serve as command central for the project and then took a systematic
approach to dividing the content into the relevant buckets:

1.  First, I tagged all the content in the master database by type
    (blog, podcast, etc.), original URL, and relevant chapter topic(s).

2.  Next, I created separate pages for each chapter outline where I
    captured the high-level points to cover, essentially placeholder
    docs to organize my thoughts on structure.

3.  Within the pages for each chapter, I created a "linked database" --
    a synced copy of the master database -- which only displayed the
    intermediate packets tagged for that chapter. Notion allows you to
    filter your databases like an Excel spreadsheet, showing only the
    pieces of content that are tagged with "Sales" or "Marketing," for
    example.

4.  Finally, using NotionAI, I generated AI summaries of every piece of
    content in the database to give me a bird's-eye view of the content
    related to each chapter.

    Thus, every chapter had its own page, containing an efficient
    at-a-glance overview of the content relevant to that chapter, along
    with my broad notes on that chapter. These filtered database views
    gave me the equivalent of our timestamped outline from the previous
    section -- a map of the terrain and the rough material I was working
    with. With this system, I could see both the forest *and* the trees:
    The AI summaries gave me a sense of the overarching ideas, and I
    could zoom in on the most relevant details from the source material
    with one click to get a more detailed view.

### What to Do When the Book's Outline is Unclear

In Jason's case, the book outline was obvious from the start. Each
chapter would put his spin on a different department within a tech
company. This gave us enough structure to begin organizing the
intermediate packets into the relevant chapters on Day 1. But sometimes
the overarching structure of the book is less apparent. When you lack a
clear picture of this "macro-outline," you can use AI as a reasoning
engine to offer powerful assistance. Claude can handle an abundance of
amorphous source material and propose a logical reorganization for the
content.

For this task, I again utilize Notion's AI database properties --
columns within the content database that generate automatic summaries or
key information for each row or entry. These properties take whatever
source material is housed within the pages of your database (i.e.,
transcripts, articles, etc.) as the context for the prompt you apply to
the entire column. Beyond summarizing, you can craft custom AI
properties thatÂ extract specific content, such as a list of keywords or
quotes related to a specific topic.

<figure>
<img src="./book_media/media/image111.png"
style="width:4.5in;height:3.87014in"
alt="A screenshot of a computer Description automatically generated" />
<figcaption><p>A filtered view of a database in Notion with custom AI
properties for summary and keywords, derived from the contents of each
entry.</p></figcaption>
</figure>

After creating these properties and populating the content database with
AI summaries, I copy and paste the titles of the packets, along with
summaries and keywords for all of the entries, into Claude with some
broad context on the aims of my book.

![](./book_media/media/image113.svg){width="4.5in" height="3.175in"}

With this prompt, AI inspects the summaries for recurring themes among
these fragments, proposing potential chapter groupings. The more context
bullet points you provide, the better the output will be. Context might
include any hunches you already have about the logical structure of the
content or topics you are confident will become chapters. Here, it helps
to include your purpose for writing the book or the "main point."

This stage of the outlining process with AI assistance is an exercise in
information architecture. We assemble an expanse of raw material from
our existing content body to supply the foundational blocks. Claude's
capacities for pattern recognition and summarization help identify the
weight-bearing walls to erect the overall book structure.

As with writing articles, developing the macro-outline requires
iterative feedback. You'll need to refine the AI's initial suggestions,
edit the outline based on your understanding, and provide directions for
improvements. Queries like "What's missing from this outline?" or "Does
this re-ordering make sense?" can guide the AI to refine its
suggestions. Flexibility is your ally -- you can always adjust and
reorder chapter headers as the book takes shape in the convergent phases
of distilling and expressing.

As you create this macro-outline, you can begin to consider the main
points within each chapter alongside the logical ordering of chapters to
make the main point of the book. If the point of the book, or of the
individual chapters, feels unclear or underdeveloped, you may need to go
back to the "capture" stage until you have enough relevant material to
suggest an outline for the whole book, and the chapters within. This can
be a valuable exercise to spotlight gaps in your outline, even before
you have all of the necessary material.

Whether you use Notion or notecards, you need a system to capture ideas
that can later be organized into the foundations of a book. AI tools can
accelerate the process compared to analog methods, but the important
thing is that you have an easy, consistent way to jot down thoughts as
they arise so they can be harvested later. There is no one-size-fits-all
system, but you can download the basic Notion template I use for
organizing content for book writing projects at my website. I can also
advise on how to customize your workspace to balance the power of AI
with the simplicity of notecards. The goal is to make writing your book
feel less like a marathon slog and more like snapping together the
building blocks you've already created over time. Once your content
database is assembled -- or at least 80 percent done -- you know what to
do next, or at least who to call if you need help with the final 20
percent. Although I'm high tech when it comes to my second brain, I'm
old fashioned in that I still prefer phone to email. You can text or
call me at (415) 717-5370 and I will respond. You can also reach out via
my website, www.vergili.us, or email me at chdeist@gmail.com.

[Chapter 15]{.underline}

[]{#_Toc152566411 .anchor}Distill & Express

Bridging the Archipelago into Coherent Chapters

"Bad authors dilute their ideas to fill a book.

Brilliant authors distill their ideas to fit into a book."

--Â Alex Wieckowski, founder of \@Alexandbooks\_

The blank pageÂ stares at you -- cursor blinking. You stare back, also
blinking. You know that you have important ideas that need to be shared.
But you're paralyzed by a vague fear. How can you translate the jumble
of thoughts in your mind into polished prose? How can you quiet the
inner critic for long enough to get a decent draft down on paper?

The ancient Greeks believed creativity to be a gift from the Muses, nine
goddesses who were unpredictable by nature, sometimes whispering
brilliance in their subjects' ears and other times remaining silent.
Writers have always struggled with the unpredictability of their
inspiration, facing the challenge of the blank page -- not knowing where
to begin or what to do in the absence of that spark. It's tempting to
think of inspiration and creativity as something outside of us rather
than an internal process that demands real work and effort.

Against this view, the prolific historian, David McCullough -- known for
epics like *1776* -- once remarked, "Writing is thinking. To write well
is to think clearly. That's why it's so hard."

Let me repeat: Writing *is* thinking. And thinking is *hard*.

Even when you manage to get your ideas down, the hardest part about
writing remains: deciding what is essential to the reader and what can
be cut. My theory on "writer's block" is that most people don't struggle
with a shortage of ideas. Rather, they are afraid that in expressing
them in a stream-of-consciousness style, they will end up with something
that makes less sense than it did in their head, and it will take longer
to rework and edit than it did to type out. I've had this experience
before.

The system we are employing sidesteps this pitfall by capturing all of
the relevant source materials first, knowing the initial order is not
final. Through phases of capture, organization, distillation, and
expression, we systematically rework and refine the raw ingredients into
a polished final product.

With the broad book outline set and materials filtered into chapters,
we're ready to transition from gathering content to distilling and
expressing the essence of each section. Our objective now is to sculpt
the divergent ideas and themes we've captured into focused,
chapter-specific narratives. The chapter headers and preliminary outline
shines enough light to embark on a selective journey of convergence with
the content, identifying pieces aligned to each theme and setting aside
the rest.

## Assembling Your Archipelagos of Ideas

As Tiago Forte writes, once you have a critical mass of ideas to work
with, "you switch decisively into convergent mode and link them together
in a way that makes sense."

The first step in distilling this raw content is to create a separate
document for each chapter. Drawing from Forte's concept of "archipelagos
of ideas," these documents will house related but disjointed material
from our content database -- a mixture of original writing and curated
quotes. Much like a brain dump, these documents allow us to gather
possibilities before carving out the key points.

As creativity scholar Steven Johnson explains, starting each chapter as
"a kind of archipelago of inspiring quotes" makes the vast empty canvas
less daunting: "All I have to do is build bridges between the islands."
Rather than confronting a terrifying blank page or empty document, we
have fertile soil from which to cultivate the chapter's direction.

While gathering ideas is a divergent exercise, organizing this
information requires convergent thinking to funnel down to the most
relevant points. So this stage balances widening and narrowing the
aperture as we distill our master content database into chapter-specific
archipelagos.

As we gather possibilities into these documents, we can pull verbatim
quotations, passages, and examples liberally from the intermediate
packets assembled in our content database. Even lengthy excerpts are
fair game to port over at this divergent stage. We extract anything that
might have a place in the final outline.

Each chapter overview -- your annotated archipelago of ideas --
functions like the condensed Cheat Sheet from our article writing
framework, only synthesizing a great deal more source material. Once
assembled, these documents enable us to create an initial outline for
each chapter with Claude's assistance.

With the raw ingredients gathered, the next step is to employ Claude to
start structuring this mixture of quotes, ideas, and passages gathered
into the foundations of a chapter, using a prompt like this:

![](./book_media/media/image115.svg){width="4.5in"
height="3.6326388888888888in"}

You can then rearrange the headers and points as you see fit and then
ask Claude to take another pass at organizing the content in the most
logical order, with more supporting details. See what order it suggests
right off the bat. Don't get stuck on the original high-level
archipelago if the content starts to pull in a different direction once
you zoom in. Be willing to reorganize sections and move entire blocks
around as you write if you find better connections and through lines.
Your outline is a guide, not a straitjacket.

Once you are satisfied with a high-level outline, the next level of
distillation involves assembling all of the relevant ideas and points
underneath the relevant headers. From here, the process of formulating a
detailed outline and drafting the chapter is virtually identical to the
steps for writing an article -- from specifying the desired voice to
drafting one section at a time. Remember: each chapter should have a
clear point, a logical structure to support that point, a hook to entice
the reader, and a concluding call to action. The biggest difference
between an article and a book chapter -- other than length -- is that
the call to action at the end of most chapters will be the invitation to
your reader to continue reading to the next chapter.

![A screenshot of a computer Description automatically
generated](./book_media/media/image116.png){width="4.5in"
height="3.5680555555555555in"}

A view of the outline database for this book, with summaries and key
info for each chapter. I use this view to provide necessary context on
the entire book when starting a new chapter.

As with all hooks and conclusions, transitions between chapters always
require special additional attention. For each new chapter that I'm
working on, I start a new conversation with Claude. However, it helps
provide some context of where we've been and are going. Remember that
while each chapter will have its own main idea and supporting points,
these chapters exist within a broader narrative that serves the Ultimate
Main Point that the book is about. One way to retain continuity between
chapters is by giving Claude the previous chapter in full and mentioning
that you will be continuing from where the previous chapter left off. A
more comprehensive method is to create a Notion database with an entry
or page for each chapter. Title each chapter and create an AI summary
property. Then, copy and paste the chapter names and summaries in
chronological order and share this list with Claude at the beginning of
the conversation. This way, the conversation is situated within the
context of the book, and the model can make connections to previous
parts.

With this system, you never have to struggle against writer's block
again. If you do get stuck in the process of writing your chapters, go
back and re-read the chapters on expressing and refining in Part 3 for
the details of how bring your outline to life in successive stages.

Ask yourself: have you defined the main point of the entire book, as
well as the individual chapters? If not, iterate there.

Have you outlined the key points in detail, in a logical order? The bulk
of your time should be spent here. You may have to wrestle with your
material for a time to see how it all fits together. But it's better to
do this wrestling in the outlining phase than after you've invested the
time in writing chapter drafts. Once you put the words on the page as
anything close to prose, it's easy to get attached to them. Rewriting
becomes a more painful process as you are forced to not only redouble
your efforts but also "drown your babies" that no longer fit within the
new outline.

An ounce of prevention is worth a pound of cure. The more selective you
are in your distillation, the less you'll have to work to serve your
readers with the essential information and none of the fluff.

[]{#_Toc152566412 .anchor}

[Conclusion]{.underline}

WHY WRITE A BOOK?

On Becoming Irreplaceable

"The illiterate of the 21st century will not be those who cannot read
and write, but those who cannot learn, unlearn, and relearn."

-- Alvin Toffler, American futurist

An author's primary duty -- before setting pen to page -- is to act as a
conduit for channeling ideas from "out there" in the real world onto the
page in a way that renders them useful and actionable to other people.
Committing to writing a book is like positioning a lightning rod or
antenna atop your head. Your subconscious begins to seek out relevant
information. You become attuned to fleeting ideas that might find a
permanent home within your book's pages. Stray thoughts converge into a
high-voltage signal that then powers your pen. When the writing begins,
your ideas flow from a mind primed to give shape to its vision.

Artificial intelligence, combined with the system of transformation I've
laid out in this book, makes it easier than ever to write a book. But it
still takes time and effort. Before committing, you would be wise to
reflect on your motives.

My reasons for writing this book were twofold, and both revolve around
the idea that authority is the ultimate resource in the AI era.

First, if I've succeeded, this book will convey a sense of my authority
on the topic of AI-assisted writing.

But my second and deeper motivation for writing it was to structure and
refine my writing method into a step-by-step system -- a replicable and
useful body of knowledge. In organizing the information, I had to take a
detailed inventory of the kinds of prompts and sequences I've used to
solve my own problems and do my job better. In this way, **it was the
act of writing this book that has made me an authority** (at least
inasmuch as anyone can be an authority on AI this early in its
development).

In several places in the book, I didn't see a clear way to communicate
my system, indicating that I had not yet thought through the steps
involved. This forced me to stop and think, often iterating with AI to
hone the ideas until they made sense. This struggle is not an obstacle
to be avoided. It's often the missing ingredient that transforms you
into the expert -- not just *an* expert. *The* expert: the one who
"wrote the book on \<X\>."

Ryan Holiday was right: the obstacle is the way. Overcoming difficulties
unlocks our greatest transformations. Anyone can produce passable prose
with AI. But few will invest the rigor needed to craft exceptional,
authoritative content. If you want to make your job safe from the coming
disruption, you will need to synthesize your own knowledge -- apart from
the training data -- and then figure out how to use AI to make it clear
and useful.

## Done-With-You: The Alternative to Ghostwriting

In this book, we've navigated a long road filled with diverse tools and
prompting techniques to reach this endpoint. The journey to write a book
might appear daunting, and the methods presented -- from advanced
prompting techniques to information architecture -- do have a learning
curve. Yet, the beauty of the CODER's approach to writing is that once
your systems are in place, it will soon feel natural. Less than a year
after writing my first prompts, it's hard for me to imagine returning to
the old writing method. After some initial experimentation, I trust that
the same will be true for you.

To bridge the gap between comprehending and applying these concepts, I
offer a done-*with*-you service as a less intensive version of my
done-for-you (ghostwriting) offering. In short, I will help you set up
the essential databases and walk you through this process in a way that
is tailored to your content and vision for your book. In this way, your
book will remain *yours* even as we accelerate it to completion.

If you want to dive in on your own, my website -- www.Vergili.us
--features a digital library of the most up-to-date prompts in this
book, and the Notion templates that I use in my workflows. As this
system evolves, I will make future versions of this book available to
anyone who purchased this first edition.

Stay tuned for the release of my self-paced course featuring detailed
over-the-shoulder tutorials so you can see how to apply these steps to
your own content.

Lastly, my periodic newsletter will keep you up-to-date on the latest
developments in AI that are most relevant for content creators looking
to "future-proof" their creative careers in the coming AI/automation
era.

## Sharing the Lightning

Even as new tools and more powerful large language models emerge, the
fundamental principles will remain the same:

1.  A human using a computer as a tool will always be more powerful than
    a machine alone.

2.  AI will always need your guiding hand and unique source material to
    produce novel content.

3.  Transformation, not generation, is the key to unlocking the secrets
    of AI alchemy.

If I've made "the point" clearly, you should now possess a deeper
understanding of the magnitude of the change that AI is bringing about
in the broader economy, and in writing specifically. However,
understanding just these three points will allow you to navigate the
future with confidence.

I hope you will embrace this new technology with excitement at the
possibilities and a keen awareness of the responsibility of wielding
such powerful tools.

Your words can move people to action. All the more so when you augment
your abilities to produce a "quantity of quality" content and obtain the
authority of a published author. Use your new powers of "Sourcery" for
good -- don't squander them on superficial click-bait -- churning out
heaps of junk articles to appease the SEO gods. Instead, contribute to
the body of useful knowledge. Share whatever unique perspective that has
remained trapped inside of you until now because the obstacles felt too
high.

While AI tools can make the creative process more efficient, the best
writing will always result from the human struggle to transform abstract
notions in one's mind into something tangible and legible that can
change the reader in some way for the better. I have always embraced
this struggle and found writing to be the best aid for thinking.

Technologists and philosophers can debate whether the capabilities of
artificial intelligence constitute true thinking and understanding. But
a certain kind of thinking is and will remain the exclusive domain and
final vocation of humans. Don't let your best thinking go to waste. This
raw stuff of human experience is worth something and,Â in the end, it may
be the *only* thing that matters. So free those captive ideas. Then, use
AI as a tool to capture, organize, distill, express, and refine them
until the masterpiece within you is liberated. The world will be a much
richer place for it.

![](./book_media/media/image118.svg){width="2.7420483377077867in"
height="4.883333333333334in"}

The Atlas, by Michelangelo

[]{#_Toc152566413 .anchor}Acknowledgements

I would like to express my deepest gratitude to my wife, Emma, whose
patience was my anchor throughout the ebbs and flows of the AI hype
cycle. A special acknowledgment must be extended to my mom, Karen, and
George Boreas, whose insightful feedback on the early drafts was
invaluable. I am indebted to by the intellectual contributions of Joshua
Lisec and Tiago Forte, whose frameworks for writing and creativity have
been a foundational element in my work. For the numerous stimulating
discussions on AI's first principles, my thanks go to Brownrygg Woolls
and Timothy Telleen-Lawton. The team at Anthropic deserves recognition
for making Claude accessible to the public and providing me early access
in 2023. Finally, I am grateful to my father, John Deist, who instilled
in me a love of writing and taught me to omit surplus words.

About the Author

Charlie Deist is a writer, producer, and creator of Vergilius
(http://vergili.us) -- an AI-first publishing company specializing in
transforming podcasts to prose. Charlie has worked in the podcast
industry since 2010 and has produced over a dozen books using
transcripts as source material for his clients.

In 2020, Charlie published the fitness philosophy book *Hormetics:
Physical Fitness for Free People*. He applies the concept of "good
stress" -- known as hormesis -- to exercise, diet, sleep, and lifestyle.

He lives in Northern California with his wife and three children.

[^1]: An observation made by Intel co-founder Gordon Moore that the
    number of transistors on a microchip doubles approximately every two
    years, leading to exponential growth in computing power.

[^2]: To enable dictation on a Mac, go to System Settings â†’ Keyboard,
    and toggle the "Dictation" button. The default shortcut is to
    double-tap the control key (bottom left key). This allows you to
    start dictating directly into any document on your computer.

[^3]: If you use [Otter.ai](http://otter.ai/) for transcription, you'll
    get an automatically generated timestamped outline along with your
    transcript. If you're satisfied with the output, you can paste its
    outline above your transcript and skip this step.

[^4]: Remember, this prompt, and all the others in this chapter are not
    meant as copy-paste templates, but as guidelines for you to come up
    with your own prompts based on your own needs. If the podcast/video
    features just your own opinions, and no guest, adjust it
    accordingly.

[^5]: [Swipefile.com](http://Swipefile.com), for example, features real
    marketing campaigns and viral articles you can study and borrow for
    your own personal swipe file.

[^6]: Forte, Tiago. *Building a Second Brain: A Proven Method to
    Organize Your Digital Life and Unlock Your Creative Potential* (p.
    172).
